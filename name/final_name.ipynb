{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e3389996",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fitz\n",
    "import pytesseract\n",
    "from pdf2image import convert_from_path\n",
    "import tempfile\n",
    "import os\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "import json\n",
    "\n",
    "# Load OpenAI API key from .env file\n",
    "load_dotenv()\n",
    "client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "\n",
    "\n",
    "# 提取 PDF 前后页文本\n",
    "def extract_front_back_text(pdf_path, front_n=5, back_n=5, dpi=400):\n",
    "    try:\n",
    "        doc = fitz.open(str(pdf_path))\n",
    "        texts = []\n",
    "        for i in range(min(front_n, len(doc))):\n",
    "            texts.append(doc[i].get_text())\n",
    "        for i in range(max(0, len(doc) - back_n), len(doc)):\n",
    "            texts.append(doc[i].get_text())\n",
    "        doc.close()\n",
    "        full_text = \"\\n\".join(texts)\n",
    "        if len(full_text.strip()) < 100:\n",
    "            raise ValueError(\"Too short, fallback to OCR.\")\n",
    "        return full_text\n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ Fallback to OCR on: {pdf_path.name} due to {str(e)}\")\n",
    "        return extract_text_with_ocr(pdf_path, front_n, back_n, dpi)\n",
    "\n",
    "def extract_text_with_ocr(pdf_path, front_n=5, back_n=5, dpi=400):\n",
    "    import warnings\n",
    "    from pdf2image.exceptions import PDFPageCountError\n",
    "    try:\n",
    "        with tempfile.TemporaryDirectory() as path:\n",
    "            try:\n",
    "                images = convert_from_path(str(pdf_path), dpi=dpi, output_folder=path)\n",
    "            except PDFPageCountError as e:\n",
    "                return f\"OCR ERROR: PDF structure invalid – {str(e)}\"\n",
    "            except Exception as e:\n",
    "                return f\"OCR ERROR: {str(e)}\"\n",
    "\n",
    "            total_pages = len(images)\n",
    "            if total_pages == 0:\n",
    "                return \"OCR ERROR: No images extracted\"\n",
    "\n",
    "            selected = images[:front_n] + images[-back_n:]\n",
    "            texts = []\n",
    "            for img in selected:\n",
    "                img = img.convert(\"L\")  # 灰度增强\n",
    "                text = pytesseract.image_to_string(img, lang=\"eng\")\n",
    "                texts.append(text)\n",
    "            return \"\\n\".join(texts)\n",
    "\n",
    "    except Exception as e:\n",
    "        return f\"OCR ERROR (outer): {str(e)}\"\n",
    "\n",
    "\n",
    "def extract_company_or_publisher_with_gpt(text):\n",
    "    import json\n",
    "\n",
    "    # 第一阶段：提取公司名称、别名、国家\n",
    "    primary_prompt = f\"\"\"\n",
    "You are a corporate reporting analyst.\n",
    "\n",
    "From the first and last pages of a corporate report, extract the following:\n",
    "1. The **official company name** that issued the report.\n",
    "2. A list of **other names** referring to the company (abbreviations, group name, acronyms, etc.).\n",
    "3. The **country** where the company is headquartered.\n",
    "4. A brief **reasoning** explaining your extraction.\n",
    "\n",
    "Return a JSON object like this:\n",
    "{{\n",
    "  \"company_name\": \"...\",\n",
    "  \"other_names\": [\"...\", \"...\"],\n",
    "  \"country\": \"...\",\n",
    "  \"reasoning\": \"...\"\n",
    "}}\n",
    "\n",
    "If the company name is not found, return:\n",
    "{{\n",
    "  \"company_name\": \"UNKNOWN\",\n",
    "  \"other_names\": [],\n",
    "  \"country\": \"UNKNOWN\",\n",
    "  \"reasoning\": \"No indication of the company in the text.\"\n",
    "}}\n",
    "\n",
    "Text:\n",
    "{text}\n",
    "\"\"\"\n",
    "\n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-4.1\",  # 更稳定\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are an expert in ESG and corporate reporting.\"},\n",
    "                {\"role\": \"user\", \"content\": primary_prompt}\n",
    "            ],\n",
    "            temperature=0\n",
    "        )\n",
    "        content = response.choices[0].message.content.strip()\n",
    "        result = json.loads(content)\n",
    "    except Exception as e:\n",
    "        return {\n",
    "            \"company_name\": \"GPT_ERROR\",\n",
    "            \"other_names\": [],\n",
    "            \"country\": \"GPT_ERROR\",\n",
    "            \"reasoning\": str(e),\n",
    "            \"publisher\": None\n",
    "        }\n",
    "    except json.JSONDecodeError:\n",
    "        return {\n",
    "            \"company_name\": \"PARSE_ERROR\",\n",
    "            \"other_names\": [],\n",
    "            \"country\": \"PARSE_ERROR\",\n",
    "            \"reasoning\": f\"Raw response: {content}\",\n",
    "            \"publisher\": None\n",
    "        }\n",
    "\n",
    "    # 第二阶段：若无法识别公司名，尝试提取 publisher\n",
    "    if result.get(\"company_name\", \"\").upper() == \"UNKNOWN\":\n",
    "        try:\n",
    "            secondary_prompt = f\"\"\"\n",
    "This report was not issued by a company but possibly by a public institution or academic body.\n",
    "\n",
    "From the following text, extract the **publisher** and return:\n",
    "{{ \"publisher\": \"...\" }}\n",
    "\n",
    "If not found:\n",
    "{{ \"publisher\": \"UNKNOWN\" }}\n",
    "\n",
    "Text:\n",
    "{text}\n",
    "\"\"\"\n",
    "            response2 = client.chat.completions.create(\n",
    "                model=\"gpt-4.1\",\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": \"You are an expert in institutional publishing.\"},\n",
    "                    {\"role\": \"user\", \"content\": secondary_prompt}\n",
    "                ],\n",
    "                temperature=0\n",
    "            )\n",
    "            content2 = response2.choices[0].message.content.strip()\n",
    "            pub_result = json.loads(content2)\n",
    "            result[\"publisher\"] = pub_result.get(\"publisher\", \"UNKNOWN\")\n",
    "        except Exception as e:\n",
    "            result[\"publisher\"] = f\"GPT_ERROR: {str(e)}\"\n",
    "    else:\n",
    "        result[\"publisher\"] = None\n",
    "\n",
    "    # 清理字段\n",
    "    if result.get(\"company_name\", \"\").upper() == \"UNKNOWN\":\n",
    "        result[\"company_name\"] = \"\"\n",
    "    if not isinstance(result.get(\"other_names\"), list):\n",
    "        result[\"other_names\"] = []\n",
    "    if \"country\" not in result or not isinstance(result[\"country\"], str):\n",
    "        result[\"country\"] = \"UNKNOWN\"\n",
    "\n",
    "    return result\n",
    "\n",
    "def process_folder_with_gpt_and_type(pdf_folder, output_path):\n",
    "    results = []\n",
    "    pdf_folder = Path(pdf_folder)\n",
    "    pdf_files = list(pdf_folder.glob(\"*.pdf\"))\n",
    "\n",
    "    for pdf in tqdm(pdf_files, desc=\"Classifying reports\"):\n",
    "        text = extract_front_back_text(pdf)\n",
    "        result = extract_company_or_publisher_with_gpt(text)\n",
    "        results.append({\n",
    "            \"file_name\": pdf.name,\n",
    "            \"company_name\": result[\"company_name\"],\n",
    "            \"other_names\": \"; \".join(result.get(\"other_names\", [])),  # 用分号拼接方便输出\n",
    "            \"publisher\": result.get(\"publisher\", None),\n",
    "            \"reasoning\": result[\"reasoning\"],\n",
    "            \"country\": result[\"country\"],\n",
    "        })\n",
    "\n",
    "    df = pd.DataFrame(results)\n",
    "    df.to_csv(output_path, index=False)\n",
    "    print(f\"✅ Saved to {output_path}\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d315525",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Classifying reports:  20%|█▉        | 251/1277 [27:25<2:29:51,  8.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ Fallback to OCR on: Unknown_adbi-managing-transition-low-carbon-economy_087is5zy.pdf due to Too short, fallback to OCR.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Classifying reports:  20%|██        | 256/1277 [28:01<2:33:32,  9.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MuPDF error: format error: cmsOpenProfileFromMem failed\n",
      "\n",
      "MuPDF error: format error: cmsOpenProfileFromMem failed\n",
      "\n",
      "MuPDF error: format error: cmsOpenProfileFromMem failed\n",
      "\n",
      "MuPDF error: format error: cmsOpenProfileFromMem failed\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Classifying reports:  20%|██        | 257/1277 [28:11<2:36:06,  9.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ Fallback to OCR on: Unknown_2014SustainRpt_FNL_lr_7mrwsfm7.pdf due to Too short, fallback to OCR.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Classifying reports:  28%|██▊       | 360/1277 [38:33<1:31:06,  5.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ Fallback to OCR on: Hansae_Yes24_Holdings_Co_Ltd_HANSAE20YES2420HOLDINGS20ESG20REPORT202022_th5kzsfk.pdf due to Too short, fallback to OCR.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Classifying reports:  34%|███▎      | 430/1277 [44:43<1:04:52,  4.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ Fallback to OCR on: Home_Inns__Hotels_Management_Inc_Barclays_Bank_PLC_Annual_Report_202014_5lj1epic.pdf due to Too short, fallback to OCR.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Classifying reports:  39%|███▉      | 498/1277 [51:30<1:11:50,  5.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ Fallback to OCR on: Unknown_adp07-sus-fr_95qx6prh.pdf due to Too short, fallback to OCR.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Classifying reports:  53%|█████▎    | 672/1277 [1:10:49<44:41,  4.43s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ Fallback to OCR on: Armstrong_Flooring_Inc_SustainabilityReport-2020_kot54emv.pdf due to Too short, fallback to OCR.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Classifying reports:  57%|█████▋    | 724/1277 [1:16:06<52:09,  5.66s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MuPDF error: format error: object is not a stream\n",
      "\n",
      "MuPDF error: format error: object is not a stream\n",
      "\n",
      "MuPDF error: format error: object is not a stream\n",
      "\n",
      "MuPDF error: format error: object is not a stream\n",
      "\n",
      "MuPDF error: format error: object is not a stream\n",
      "\n",
      "MuPDF error: format error: object is not a stream\n",
      "\n",
      "MuPDF error: format error: object is not a stream\n",
      "\n",
      "MuPDF error: format error: object is not a stream\n",
      "\n",
      "MuPDF error: format error: object is not a stream\n",
      "\n",
      "MuPDF error: format error: object is not a stream\n",
      "\n",
      "MuPDF error: format error: object is not a stream\n",
      "\n",
      "MuPDF error: format error: object is not a stream\n",
      "\n",
      "MuPDF error: format error: object is not a stream\n",
      "\n",
      "MuPDF error: format error: object is not a stream\n",
      "\n",
      "MuPDF error: format error: object is not a stream\n",
      "\n",
      "MuPDF error: format error: object is not a stream\n",
      "\n",
      "MuPDF error: format error: object is not a stream\n",
      "\n",
      "MuPDF error: format error: object is not a stream\n",
      "\n",
      "MuPDF error: format error: object is not a stream\n",
      "\n",
      "MuPDF error: format error: object is not a stream\n",
      "\n",
      "MuPDF error: format error: object is not a stream\n",
      "\n",
      "MuPDF error: format error: object is not a stream\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Classifying reports:  60%|██████    | 771/1277 [1:20:37<33:48,  4.01s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ Fallback to OCR on: Tam_Jai_International_Co_Ltd_2022083101184_go5rbp4a.pdf due to Too short, fallback to OCR.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Classifying reports:  70%|███████   | 896/1277 [1:33:39<27:12,  4.28s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ Fallback to OCR on: Hyosung_Corp_SR_2020_en_8g98j6gk.pdf due to Too short, fallback to OCR.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Classifying reports:  76%|███████▋  | 974/1277 [1:42:01<19:38,  3.89s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ Fallback to OCR on: Boryung_Corporation_EBB3B4EBA0B920ECA780EC868DEAB080EB8AA5EAB2BDEC9881EBB3B4EAB3A0EC849CEC9881EBACB8_ebpit5lz.pdf due to Too short, fallback to OCR.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Classifying reports:  77%|███████▋  | 987/1277 [1:42:43<16:14,  3.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ Fallback to OCR on: Arvind_Ltd_Arvind_AR_2022-23_0_iwp4673c.pdf due to Too short, fallback to OCR.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Classifying reports:  87%|████████▋ | 1106/1277 [1:52:01<11:11,  3.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ Fallback to OCR on: EKI_Energy_Services_Limited_69298543284_zj7y1tjh.pdf due to Too short, fallback to OCR.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Classifying reports:  88%|████████▊ | 1122/1277 [1:53:24<16:16,  6.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ Fallback to OCR on: Unknown_23076_Whitbread_AR2020_web_0v2mxh4f.pdf due to Too short, fallback to OCR.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Classifying reports:  90%|████████▉ | 1149/1277 [1:55:30<09:11,  4.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MuPDF error: format error: cmsOpenProfileFromMem failed\n",
      "\n",
      "MuPDF error: format error: cmsOpenProfileFromMem failed\n",
      "\n",
      "MuPDF error: format error: cmsOpenProfileFromMem failed\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Classifying reports:  91%|█████████▏| 1168/1277 [1:56:51<06:32,  3.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MuPDF error: format error: No default Layer config\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Classifying reports:  95%|█████████▍| 1209/1277 [2:00:06<04:55,  4.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ Fallback to OCR on: Unknown_2023042101335_kyzhtmjn.pdf due to Too short, fallback to OCR.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Classifying reports:  97%|█████████▋| 1239/1277 [2:02:52<03:55,  6.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ Fallback to OCR on: Titan_Company_Ltd_Annual20Report202013_p4r8w07u.pdf due to Too short, fallback to OCR.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Classifying reports:  99%|█████████▉| 1269/1277 [2:05:28<00:25,  3.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ Fallback to OCR on: BASF_SE_2012_BASF_Report_lmq79gwn.pdf due to Too short, fallback to OCR.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Classifying reports: 100%|██████████| 1277/1277 [2:05:57<00:00,  5.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved to output/company_name_gpt_results3-1.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>company_name</th>\n",
       "      <th>other_names</th>\n",
       "      <th>publisher</th>\n",
       "      <th>reasoning</th>\n",
       "      <th>country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Unknown_8f57f855-11bb-496d-9916-91ff88cb537b_s...</td>\n",
       "      <td>Paramount Global</td>\n",
       "      <td>Paramount; the Company; ViacomCBS Inc.; Viacom...</td>\n",
       "      <td>None</td>\n",
       "      <td>The first page of the report clearly states 'P...</td>\n",
       "      <td>United States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Toyota_Industries_Corp_environment2004_40h96hj...</td>\n",
       "      <td>Toyota Industries Corporation</td>\n",
       "      <td>Toyota Industries; Toyota Industries Group; To...</td>\n",
       "      <td>None</td>\n",
       "      <td>The official company name 'Toyota Industries C...</td>\n",
       "      <td>Japan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Knoll_Inc_Knoll_Enviro_2008_gqetdkb7.pdf</td>\n",
       "      <td>Knoll, Inc.</td>\n",
       "      <td>Knoll; Knoll Group; KnollStudio; KnollTextiles...</td>\n",
       "      <td>None</td>\n",
       "      <td>The first page of the report includes a quote ...</td>\n",
       "      <td>United States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Intel_Corp__fwws0wtm.pdf</td>\n",
       "      <td>Intel Corporation</td>\n",
       "      <td>Intel; Intel Foundation; Intel Group</td>\n",
       "      <td>None</td>\n",
       "      <td>The first page of the report refers to 'Intel'...</td>\n",
       "      <td>United States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Unknown_2020_SEBANG20SUSTAINABILITY20REPORT_EN...</td>\n",
       "      <td>SEBANG Co., Ltd.</td>\n",
       "      <td>SEBANG; SEBANG Group; SEBANG Express; SEBANG VINA</td>\n",
       "      <td>None</td>\n",
       "      <td>The official company name 'SEBANG Co., Ltd.' i...</td>\n",
       "      <td>South Korea</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1272</th>\n",
       "      <td>Logwin_AG_CSR_Report_2021_en_rbp4aney.pdf</td>\n",
       "      <td>Logwin AG</td>\n",
       "      <td>Logwin; Logwin Group; Logwin Corporation</td>\n",
       "      <td>None</td>\n",
       "      <td>On page 3, the text states: 'Logwin AG, with h...</td>\n",
       "      <td>Luxembourg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1273</th>\n",
       "      <td>Shanghai_Electric_Group_Co_Ltd_95909_s0uqoqkj.pdf</td>\n",
       "      <td>Shanghai Electric Group Co., Ltd</td>\n",
       "      <td>Shanghai Electric; Group; Company; we</td>\n",
       "      <td>None</td>\n",
       "      <td>The official company name 'Shanghai Electric G...</td>\n",
       "      <td>China</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1274</th>\n",
       "      <td>PT_Soho_Global_Health_Tbk_Final_annual_report_...</td>\n",
       "      <td>PT Soho Global Health Tbk</td>\n",
       "      <td>SGH; Soho Global Health; Kelompok Usaha; the G...</td>\n",
       "      <td>None</td>\n",
       "      <td>The official company name 'PT Soho Global Heal...</td>\n",
       "      <td>Indonesia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1275</th>\n",
       "      <td>Banner_Corp_32banner-sustainability-report-202...</td>\n",
       "      <td>Banner Ltd.</td>\n",
       "      <td>Banner; Banner Group; Banner Group Ltd; Banner...</td>\n",
       "      <td>None</td>\n",
       "      <td>The first and last pages of the report list th...</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1276</th>\n",
       "      <td>Unknown_917947-2021-sustainability-report_ddoz...</td>\n",
       "      <td>CommScope, Inc.</td>\n",
       "      <td>CommScope; CommScope Group; COMM</td>\n",
       "      <td>None</td>\n",
       "      <td>The first and last pages of the report repeate...</td>\n",
       "      <td>United States</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1277 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              file_name  \\\n",
       "0     Unknown_8f57f855-11bb-496d-9916-91ff88cb537b_s...   \n",
       "1     Toyota_Industries_Corp_environment2004_40h96hj...   \n",
       "2              Knoll_Inc_Knoll_Enviro_2008_gqetdkb7.pdf   \n",
       "3                              Intel_Corp__fwws0wtm.pdf   \n",
       "4     Unknown_2020_SEBANG20SUSTAINABILITY20REPORT_EN...   \n",
       "...                                                 ...   \n",
       "1272          Logwin_AG_CSR_Report_2021_en_rbp4aney.pdf   \n",
       "1273  Shanghai_Electric_Group_Co_Ltd_95909_s0uqoqkj.pdf   \n",
       "1274  PT_Soho_Global_Health_Tbk_Final_annual_report_...   \n",
       "1275  Banner_Corp_32banner-sustainability-report-202...   \n",
       "1276  Unknown_917947-2021-sustainability-report_ddoz...   \n",
       "\n",
       "                          company_name  \\\n",
       "0                     Paramount Global   \n",
       "1        Toyota Industries Corporation   \n",
       "2                          Knoll, Inc.   \n",
       "3                    Intel Corporation   \n",
       "4                     SEBANG Co., Ltd.   \n",
       "...                                ...   \n",
       "1272                         Logwin AG   \n",
       "1273  Shanghai Electric Group Co., Ltd   \n",
       "1274         PT Soho Global Health Tbk   \n",
       "1275                       Banner Ltd.   \n",
       "1276                   CommScope, Inc.   \n",
       "\n",
       "                                            other_names publisher  \\\n",
       "0     Paramount; the Company; ViacomCBS Inc.; Viacom...      None   \n",
       "1     Toyota Industries; Toyota Industries Group; To...      None   \n",
       "2     Knoll; Knoll Group; KnollStudio; KnollTextiles...      None   \n",
       "3                  Intel; Intel Foundation; Intel Group      None   \n",
       "4     SEBANG; SEBANG Group; SEBANG Express; SEBANG VINA      None   \n",
       "...                                                 ...       ...   \n",
       "1272           Logwin; Logwin Group; Logwin Corporation      None   \n",
       "1273              Shanghai Electric; Group; Company; we      None   \n",
       "1274  SGH; Soho Global Health; Kelompok Usaha; the G...      None   \n",
       "1275  Banner; Banner Group; Banner Group Ltd; Banner...      None   \n",
       "1276                   CommScope; CommScope Group; COMM      None   \n",
       "\n",
       "                                              reasoning         country  \n",
       "0     The first page of the report clearly states 'P...   United States  \n",
       "1     The official company name 'Toyota Industries C...           Japan  \n",
       "2     The first page of the report includes a quote ...   United States  \n",
       "3     The first page of the report refers to 'Intel'...   United States  \n",
       "4     The official company name 'SEBANG Co., Ltd.' i...     South Korea  \n",
       "...                                                 ...             ...  \n",
       "1272  On page 3, the text states: 'Logwin AG, with h...      Luxembourg  \n",
       "1273  The official company name 'Shanghai Electric G...           China  \n",
       "1274  The official company name 'PT Soho Global Heal...       Indonesia  \n",
       "1275  The first and last pages of the report list th...  United Kingdom  \n",
       "1276  The first and last pages of the report repeate...   United States  \n",
       "\n",
       "[1277 rows x 6 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 路径替换成你的 PDF 文件夹\n",
    "# Paths\n",
    "PDF_DIR = Path(\"pdf_folder\")  # Ensure this path contains your PDFs\n",
    "OUTPUT_PATH = Path(\"output/company_name_gpt_results.csv\")\n",
    "process_folder_with_gpt_and_type(PDF_DIR, OUTPUT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35ba4a8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 公司名称提取准确率（含别名容错）：75.49%\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from difflib import SequenceMatcher\n",
    "import re\n",
    "import ast\n",
    "\n",
    "# === Step 1: 加载文件 ===\n",
    "df_pred = pd.read_csv(\"output/company_name_gpt_results3.csv\")  # 包含 company_name、other_names\n",
    "df_true = pd.read_csv(\"check/matching_gabarito_with_pdfs.csv\")  # 包含 name_2\n",
    "\n",
    "df_pred[\"filename\"] = df_pred[\"file_name\"].str.strip()\n",
    "df_true[\"filename\"] = df_true[\"pdf_path\"].str.strip()\n",
    "\n",
    "df_merged = pd.merge(df_pred, df_true, on=\"filename\", how=\"inner\")\n",
    "\n",
    "# === Step 2: 清洗函数 ===\n",
    "def _clean_name(name: str) -> str:\n",
    "    if pd.isna(name):\n",
    "        return \"\"\n",
    "    name = name.lower()\n",
    "    name = re.sub(r\"\\([^()]*\\)\", \"\", name)\n",
    "    name = re.sub(r\"[^\\w\\d\\s]\", \"\", name)\n",
    "    suffixes = [\" company\", \" companies\", \" corporation\", \" incorporated\", \" corp\", \" llc\", \" ltd\", \" inc\", \n",
    "                \" oyj\", \" intl\", \" sa\", \" lp\", \" spa\", \" sanv\", \" nv\", \" plc\", \" nvsa\", \" ptd\", \n",
    "                \" int\", \" international\", \"limited\", \"group\", \"the \", \" holdings\", \" co\"]\n",
    "    for suffix in suffixes:\n",
    "        name = name.replace(suffix, \"\")\n",
    "    name = name.replace(\"é\", \"e\").replace(\"  \", \"\").replace(\" \", \"\")\n",
    "    return re.sub(r\"[^a-zA-Z0-9]\", \"\", name)\n",
    "\n",
    "# === Step 3: 匹配函数 ===\n",
    "def fuzzy_match(clean_a, clean_b):\n",
    "    return SequenceMatcher(None, clean_a, clean_b).ratio()\n",
    "\n",
    "def get_best_match(row):\n",
    "    target = _clean_name(row[\"name_2\"])\n",
    "    main_name = _clean_name(row[\"company_name\"])\n",
    "    best_score = fuzzy_match(main_name, target)\n",
    "    best_source = \"company_name\"\n",
    "\n",
    "    # 如果提供了 other_names，就尝试匹配\n",
    "    if \"other_names\" in row and pd.notna(row[\"other_names\"]):\n",
    "        try:\n",
    "            candidates = ast.literal_eval(row[\"other_names\"]) if isinstance(row[\"other_names\"], str) else []\n",
    "        except Exception:\n",
    "            candidates = []\n",
    "        for alt in candidates:\n",
    "            alt_clean = _clean_name(alt)\n",
    "            score = fuzzy_match(alt_clean, target)\n",
    "            if score > best_score:\n",
    "                best_score = score\n",
    "                best_source = \"other_names\"\n",
    "\n",
    "    return pd.Series([best_score, best_score >= 0.85, best_source], index=[\"fuzzy_score\", \"is_correct\", \"matched_by\"])\n",
    "\n",
    "# === Step 4: 应用匹配函数 ===\n",
    "df_merged[[\"fuzzy_score\", \"is_correct\", \"matched_by\"]] = df_merged.apply(get_best_match, axis=1)\n",
    "\n",
    "# === Step 5: 输出评估表 ===\n",
    "df_eval = df_merged[[\"filename\", \"company_name\", \"other_names\", \"name_2\", \"fuzzy_score\", \"is_correct\", \"matched_by\"]]\n",
    "df_eval.to_csv(\"output/company_name_eval_with_alias.csv\", index=False)\n",
    "\n",
    "# === Step 6: 显示准确率 ===\n",
    "accuracy = df_eval[\"is_correct\"].mean()\n",
    "print(f\"✅ 公司名称提取准确率（含别名容错）：{accuracy:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04676ad4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 公司名称提取准确率（含别名匹配）：90.69%\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from difflib import SequenceMatcher\n",
    "import re\n",
    "import ast\n",
    "\n",
    "# === Step 1: 加载文件 ===\n",
    "df_pred = pd.read_csv(\"output/company_name_gpt_results3.csv\")  # 包含 company_name、other_names\n",
    "df_true = pd.read_csv(\"check/matching_gabarito_with_pdfs.csv\")  # 包含 name_2\n",
    "\n",
    "df_pred[\"filename\"] = df_pred[\"file_name\"].str.strip()\n",
    "df_true[\"filename\"] = df_true[\"pdf_path\"].str.strip()\n",
    "\n",
    "df_merged = pd.merge(df_pred, df_true, on=\"filename\", how=\"inner\")\n",
    "\n",
    "# === Step 2: 清洗函数 ===\n",
    "def _clean_name(name: str) -> str:\n",
    "    if pd.isna(name):\n",
    "        return \"\"\n",
    "    name = name.lower()\n",
    "    name = re.sub(r\"\\([^()]*\\)\", \"\", name)\n",
    "    name = re.sub(r\"[^\\w\\d\\s]\", \"\", name)\n",
    "    suffixes = [\n",
    "        \" company\", \" companies\", \" corporation\", \" incorporated\", \" corp\", \" llc\", \" ltd\", \" inc\", \n",
    "        \" oyj\", \" intl\", \" sa\", \" lp\", \" spa\", \" sanv\", \" nv\", \" plc\", \" nvsa\", \" ptd\", \n",
    "        \" int\", \" international\", \"limited\", \"group\", \"the \", \" holdings\", \" co\"\n",
    "    ]\n",
    "    for suffix in suffixes:\n",
    "        name = name.replace(suffix, \"\")\n",
    "    name = name.replace(\"é\", \"e\").replace(\"  \", \"\").replace(\" \", \"\")\n",
    "    return re.sub(r\"[^a-zA-Z0-9]\", \"\", name)\n",
    "\n",
    "# === Step 3: 匹配函数 ===\n",
    "def fuzzy_match(clean_a, clean_b):\n",
    "    return SequenceMatcher(None, clean_a, clean_b).ratio()\n",
    "def get_best_match(row):\n",
    "    target = _clean_name(row[\"name_2\"])\n",
    "    main_name = _clean_name(row[\"company_name\"])\n",
    "    best_score = fuzzy_match(main_name, target)\n",
    "    best_source = \"company_name\"\n",
    "\n",
    "    # 解析 other_names：支持列表或字符串（自动切分）\n",
    "    candidates = []\n",
    "    if \"other_names\" in row and pd.notna(row[\"other_names\"]):\n",
    "        raw = row[\"other_names\"]\n",
    "        try:\n",
    "            if isinstance(raw, str):\n",
    "                if raw.startswith(\"[\"):  # 是列表字符串\n",
    "                    candidates = ast.literal_eval(raw)\n",
    "                else:  # 否则按常见分隔符切分\n",
    "                    candidates = re.split(r\"[;,\\n]\", raw)\n",
    "            elif isinstance(raw, list):\n",
    "                candidates = raw\n",
    "        except Exception:\n",
    "            candidates = []\n",
    "\n",
    "    for alt in candidates:\n",
    "        alt_clean = _clean_name(alt)\n",
    "        score = fuzzy_match(alt_clean, target)\n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            best_source = f\"other_names ({alt.strip()})\"\n",
    "\n",
    "    return pd.Series([best_score, best_score >= 0.85, best_source], index=[\"fuzzy_score\", \"is_correct\", \"matched_by\"])\n",
    "# === Step 4: 应用匹配函数 ===\n",
    "df_merged[[\"fuzzy_score\", \"is_correct\", \"matched_by\"]] = df_merged.apply(get_best_match, axis=1)\n",
    "\n",
    "# === Step 5: 输出评估表 ===\n",
    "df_eval = df_merged[[\"filename\", \"company_name\", \"other_names\", \"name_2\", \"fuzzy_score\", \"is_correct\", \"matched_by\"]]\n",
    "df_eval.to_csv(\"eval/company_name_eval_with_alias.csv\", index=False)\n",
    "\n",
    "# === Step 6: 显示准确率 ===\n",
    "accuracy = df_eval[\"is_correct\"].mean()\n",
    "print(f\"✅ 公司名称提取准确率（含别名匹配）：{accuracy:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c023eca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['file_name', 'company_name', 'other_names', 'publisher', 'reasoning',\n",
      "       'country', 'filename', 'name', 'name_2', 'is_match',\n",
      "       'difficulty_category', 'conml', 'loc', 'GICS_level_1', 'GICS_level_2',\n",
      "       'GICS_level_3', 'predicted_company_name', 'pdf_data_lake_path',\n",
      "       'pdf_bucket_path1', 'pdf_bucket_path2', 'pdf_bucket_path3',\n",
      "       'pdf_bucket_path4', 'pdf_bucket_path5', 'pdf_path'],\n",
      "      dtype='object')\n",
      "✅ 公司名称提取准确率（含别名 + 国家辅助匹配）：90.69%\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import ast\n",
    "from difflib import SequenceMatcher\n",
    "\n",
    "# === Step 1: 加载文件 ===\n",
    "df_pred = pd.read_csv(\"output/company_name_gpt_results3.csv\")  # 包含 company_name、other_names\n",
    "df_true = pd.read_csv(\"check/matching_gabarito_with_pdfs.csv\")  # 包含 name_2\n",
    "\n",
    "df_pred[\"filename\"] = df_pred[\"file_name\"].str.strip()\n",
    "df_true[\"filename\"] = df_true[\"pdf_path\"].str.strip()\n",
    "\n",
    "\n",
    "# === Step 2: 国家简称 ↔︎ 全称映射 ===\n",
    "from iso3166 import countries_by_alpha2, countries_by_name\n",
    "def normalize_country_name(name):\n",
    "    if pd.isna(name):\n",
    "        return \"\"\n",
    "    name = name.strip().lower()\n",
    "    # 检查是否是简称\n",
    "    if name.upper() in countries_by_alpha2:\n",
    "        return countries_by_alpha2[name.upper()].name.lower()\n",
    "    # 检查是否是全称\n",
    "    for country in countries_by_name.values():\n",
    "        if name in country.name.lower():\n",
    "            return country.name.lower()\n",
    "    return name\n",
    "\n",
    "# === Step 3: 清洗函数 ===\n",
    "def _clean_name(name: str) -> str:\n",
    "    if pd.isna(name):\n",
    "        return \"\"\n",
    "    name = name.lower()\n",
    "    name = re.sub(r\"\\([^()]*\\)\", \"\", name)\n",
    "    name = re.sub(r\"[^\\w\\d\\s]\", \"\", name)\n",
    "    suffixes = [\n",
    "        \" company\", \" companies\", \" corporation\", \" incorporated\", \" corp\", \" llc\", \" ltd\", \" inc\", \n",
    "        \" oyj\", \" intl\", \" sa\", \" lp\", \" spa\", \" sanv\", \" nv\", \" plc\", \" nvsa\", \" ptd\", \n",
    "        \" int\", \" international\", \"limited\", \"group\", \"the \", \" holdings\", \" co\"\n",
    "    ]\n",
    "    for suffix in suffixes:\n",
    "        name = name.replace(suffix, \"\")\n",
    "    name = name.replace(\"é\", \"e\").replace(\"  \", \"\").replace(\" \", \"\")\n",
    "    return re.sub(r\"[^a-zA-Z0-9]\", \"\", name)\n",
    "\n",
    "def fuzzy_match(clean_a, clean_b):\n",
    "    return SequenceMatcher(None, clean_a, clean_b).ratio()\n",
    "\n",
    "def keyword_overlap_match(name1: str, name2: str) -> bool:\n",
    "    \"\"\"只保留字母+数字单词，比对是否有交集\"\"\"\n",
    "    words1 = set(re.findall(r'\\b\\w+\\b', name1.lower()))\n",
    "    words2 = set(re.findall(r'\\b\\w+\\b', name2.lower()))\n",
    "    # 排除无意义短词（如co, ltd, inc等）\n",
    "    blacklist = {\"co\", \"ltd\", \"inc\", \"group\", \"company\", \"corp\", \"corporation\", \"plc\", \"holdings\"}\n",
    "    words1 = {w for w in words1 if w not in blacklist and len(w) > 2}\n",
    "    words2 = {w for w in words2 if w not in blacklist and len(w) > 2}\n",
    "    return len(words1 & words2) > 0\n",
    "\n",
    "# === Step 4: 处理匹配逻辑（主名 + 别名 + 国家辅助）===\n",
    "def get_best_match(row):\n",
    "    target = _clean_name(row[\"name_2\"])\n",
    "    main_name = _clean_name(row[\"company_name\"])\n",
    "    best_score = fuzzy_match(main_name, target)\n",
    "    best_source = \"company_name\"\n",
    "    is_match = best_score >= 0.85\n",
    "\n",
    "    # 尝试匹配别名\n",
    "    candidates = []\n",
    "    if \"other_names\" in row and pd.notna(row[\"other_names\"]):\n",
    "        raw = row[\"other_names\"]\n",
    "        try:\n",
    "            if isinstance(raw, str):\n",
    "                if raw.startswith(\"[\"):  # 是列表字符串\n",
    "                    candidates = ast.literal_eval(raw)\n",
    "                else:  # 否则按分隔符分割\n",
    "                    candidates = re.split(r\"[;,\\n]\", raw)\n",
    "            elif isinstance(raw, list):\n",
    "                candidates = raw\n",
    "        except Exception:\n",
    "            candidates = []\n",
    "\n",
    "    for alt in candidates:\n",
    "        alt_clean = _clean_name(alt)\n",
    "        score = fuzzy_match(alt_clean, target)\n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            best_source = f\"other_names ({alt.strip()})\"\n",
    "            is_match = score >= 0.85\n",
    "\n",
    "    # 如果主名/别名都不满足阈值，则根据国家判断\n",
    "    # === 替换原来的 relaxed_by_country_match 判断部分 ===\n",
    "    if not is_match:\n",
    "        country1 = normalize_country_name(row.get(\"country\", \"\"))\n",
    "        country2 = normalize_country_name(row.get(\"Loc\", \"\"))\n",
    "        if country1 and country1 == country2:\n",
    "            if keyword_overlap_match(row[\"company_name\"], row[\"name_2\"]):\n",
    "                is_match = True\n",
    "                best_source = \"relaxed_by_country_keyword\"\n",
    "\n",
    "    return pd.Series([best_score, is_match, best_source], index=[\"fuzzy_score\", \"is_correct\", \"matched_by\"])\n",
    "\n",
    "# === Step 5: 应用匹配逻辑 ===\n",
    "df_merged[[\"fuzzy_score\", \"is_correct\", \"matched_by\"]] = df_merged.apply(get_best_match, axis=1)\n",
    "\n",
    "# === Step 6: 保存结果 ===\n",
    "df_eval = df_merged[[\"filename\", \"company_name\", \"other_names\", \"name_2\", \"country\", \"loc\", \"fuzzy_score\", \"is_correct\", \"matched_by\"]]\n",
    "df_eval.to_csv(\"eval/company_name_eval_with_country.csv\", index=False)\n",
    "\n",
    "# === Step 7: 输出准确率 ===\n",
    "accuracy = df_eval[\"is_correct\"].mean()\n",
    "print(f\"✅ 公司名称提取准确率（含别名 + 国家辅助匹配）：{accuracy:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dd051628",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loc\n",
      "USA    553\n",
      "JPN    334\n",
      "IND    274\n",
      "GBR    184\n",
      "KOR    118\n",
      "CHN    112\n",
      "CAN    102\n",
      "DEU     86\n",
      "FRA     84\n",
      "AUS     80\n",
      "HKG     60\n",
      "SGP     54\n",
      "IDN     51\n",
      "CHE     47\n",
      "ZAF     44\n",
      "SWE     41\n",
      "ITA     31\n",
      "NOR     26\n",
      "ESP     25\n",
      "NLD     20\n",
      "AUT     17\n",
      "FIN     14\n",
      "NZL     14\n",
      "POL     13\n",
      "CHL     13\n",
      "IRL     13\n",
      "BEL     12\n",
      "TUR     11\n",
      "ISR     11\n",
      "DNK      9\n",
      "MEX      8\n",
      "SAU      7\n",
      "LUX      7\n",
      "JEY      4\n",
      "MAR      4\n",
      "PRT      4\n",
      "GRC      3\n",
      "BRA      3\n",
      "COL      3\n",
      "VGB      2\n",
      "CYM      2\n",
      "BMU      2\n",
      "HRV      1\n",
      "GGY      1\n",
      "ARG      1\n",
      "LTU      1\n",
      "BGR      1\n",
      "RUS      1\n",
      "CYP      1\n",
      "CZE      1\n",
      "SVN      1\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df_true = pd.read_csv(\"check/matching_gabarito_with_pdfs.csv\")  # 包含 name_2\n",
    "print(df_true[\"loc\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "65142d6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 公司名称提取准确率（含国家宽松匹配）：95.59%\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from difflib import SequenceMatcher\n",
    "import re\n",
    "import ast\n",
    "import pycountry\n",
    "\n",
    "# === Step 1: 加载文件 ===\n",
    "df_pred = pd.read_csv(\"output/company_name_gpt_results3.csv\")  # 包含 company_name、other_names\n",
    "df_true = pd.read_csv(\"check/matching_gabarito_with_pdfs2.csv\")  # 包含 name_2\n",
    "df_pred[\"filename\"] = df_pred[\"file_name\"].str.strip()\n",
    "df_true[\"filename\"] = df_true[\"pdf_path\"].str.strip()\n",
    "\n",
    "df_merged = pd.merge(df_pred, df_true, on=\"filename\", how=\"inner\")\n",
    "\n",
    "# === Step 2: 清洗函数 ===\n",
    "def _clean_name(name: str) -> str:\n",
    "    if pd.isna(name):\n",
    "        return \"\"\n",
    "    name = name.lower()\n",
    "    name = re.sub(r\"\\([^()]*\\)\", \"\", name)\n",
    "    name = re.sub(r\"[^\\w\\d\\s]\", \"\", name)\n",
    "    suffixes = [\n",
    "        \" company\", \" companies\", \" corporation\", \" incorporated\", \" corp\", \" llc\", \" ltd\", \" inc\", \n",
    "        \" oyj\", \" intl\", \" sa\", \" lp\", \" spa\", \" sanv\", \" nv\", \" plc\", \" nvsa\", \" ptd\", \n",
    "        \" int\", \" international\", \"limited\", \"group\", \"the \", \" holdings\", \" co\"\n",
    "    ]\n",
    "    for suffix in suffixes:\n",
    "        name = name.replace(suffix, \"\")\n",
    "    return re.sub(r\"\\s+\", \" \", name).strip()\n",
    "\n",
    "def fuzzy_match(a, b):\n",
    "    return SequenceMatcher(None, a, b).ratio()\n",
    "\n",
    "def normalize_country_name(name):\n",
    "    if pd.isna(name) or not isinstance(name, str):\n",
    "        return \"\"\n",
    "    name = name.strip().lower()\n",
    "    try:\n",
    "        # 先尝试国家简称\n",
    "        country = pycountry.countries.get(alpha_2=name.upper())\n",
    "        if country:\n",
    "            return country.name.lower()\n",
    "        # 再尝试国家全称\n",
    "        country = pycountry.countries.search_fuzzy(name)[0]\n",
    "        return country.name.lower()\n",
    "    except:\n",
    "        return name.lower()\n",
    "\n",
    "def word_overlap_match(name1, name2):\n",
    "    \"\"\"返回两个名字中单词交集是否显著（≥1个有效关键词）\"\"\"\n",
    "    stopwords = {\"group\", \"holdings\", \"company\", \"limited\", \"corporation\", \"inc\", \"co\"}\n",
    "    words1 = set(re.findall(r\"\\b\\w+\\b\", name1.lower())) - stopwords\n",
    "    words2 = set(re.findall(r\"\\b\\w+\\b\", name2.lower())) - stopwords\n",
    "    return len(words1 & words2) > 0\n",
    "\n",
    "# === Step 3: 匹配函数 ===\n",
    "def get_best_match(row):\n",
    "    target = _clean_name(row[\"name_2\"])\n",
    "    main_name = _clean_name(row[\"company_name\"])\n",
    "    best_score = fuzzy_match(main_name, target)\n",
    "    best_source = \"company_name\"\n",
    "    is_match = best_score >= 0.85\n",
    "\n",
    "    # 尝试别名匹配\n",
    "    candidates = []\n",
    "    if \"other_names\" in row and pd.notna(row[\"other_names\"]):\n",
    "        raw = row[\"other_names\"]\n",
    "        try:\n",
    "            if isinstance(raw, str):\n",
    "                if raw.startswith(\"[\"):\n",
    "                    candidates = ast.literal_eval(raw)\n",
    "                else:\n",
    "                    candidates = re.split(r\"[;,\\n]\", raw)\n",
    "            elif isinstance(raw, list):\n",
    "                candidates = raw\n",
    "        except Exception:\n",
    "            candidates = []\n",
    "\n",
    "    for alt in candidates:\n",
    "        alt_clean = _clean_name(alt)\n",
    "        score = fuzzy_match(alt_clean, target)\n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            is_match = score >= 0.85\n",
    "            best_source = f\"other_names ({alt.strip()})\"\n",
    "\n",
    "    # 第三阶段：若高分匹配失败，则使用国家宽松匹配 + 单词交集\n",
    "    country1 = normalize_country_name(row.get(\"country\", \"\"))\n",
    "    country2 = normalize_country_name(row.get(\"loc\", \"\"))\n",
    "    \n",
    "    relaxed_match_applied = False\n",
    "    if not is_match and country1 and country1 == country2:\n",
    "        if word_overlap_match(row[\"company_name\"], row[\"name_2\"]):\n",
    "            is_match = True\n",
    "            best_source = \"relaxed_by_country_word_overlap\"\n",
    "            relaxed_match_applied = True\n",
    "\n",
    "    return pd.Series([\n",
    "        best_score,\n",
    "        is_match,\n",
    "        best_source,\n",
    "        country1,\n",
    "        country2,\n",
    "        relaxed_match_applied\n",
    "    ], index=[\n",
    "        \"fuzzy_score\", \"is_correct\", \"matched_by\", \n",
    "        \"normalized_country_pred\", \"normalized_country_true\", \n",
    "        \"used_relaxed_match\"\n",
    "    ])\n",
    "\n",
    "# === Step 4: 应用匹配函数 ===\n",
    "df_merged[[\n",
    "    \"fuzzy_score\", \"is_correct\", \"matched_by\", \n",
    "    \"normalized_country_pred\", \"normalized_country_true\", \n",
    "    \"used_relaxed_match\"\n",
    "]] = df_merged.apply(get_best_match, axis=1)\n",
    "\n",
    "# === Step 5: 输出表格 ===\n",
    "df_eval = df_merged[[\n",
    "    \"filename\", \"company_name\", \"other_names\", \"country\", \n",
    "    \"name_2\", \"loc\", \"normalized_country_pred\", \n",
    "    \"normalized_country_true\", \"fuzzy_score\", \"is_correct\", \n",
    "    \"matched_by\", \"used_relaxed_match\"\n",
    "]]\n",
    "df_eval.to_csv(\"eval/company_name_eval_with_country_relaxed.csv\", index=False)\n",
    "\n",
    "# === Step 6: 显示准确率 ===\n",
    "accuracy = df_eval[\"is_correct\"].mean()\n",
    "print(f\"✅ 公司名称提取准确率（含国家宽松匹配）：{accuracy:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c5d25f2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "irp_pdf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
