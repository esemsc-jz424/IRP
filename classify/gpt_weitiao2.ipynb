{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a59f48d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "60f02734",
   "metadata": {},
   "source": [
    "PDF Text  ‚îÄ‚îÄ‚îê\n",
    "            ‚îÇ\n",
    "            ‚ñº\n",
    "extract_text_from_pdf()\n",
    "            ‚îÇ\n",
    "            ‚ñº\n",
    "GPT Classification + Structural Inference (via API)\n",
    "            ‚îÇ\n",
    "            ‚ñº\n",
    "Auto-Generated Labeled Data (text + label)\n",
    "            ‚îÇ\n",
    "            ‚ñº\n",
    "Fine-tune Classifier ( BERT / RoBERTa)\n",
    "            ‚îÇ\n",
    "            ‚ñº\n",
    "Fast Local Classification Deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f6b70172",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Automatically classify PDFs using GPT and generate fine-tuned training datasets (compatible with OpenAI >= 1.0.0)\n",
    "\n",
    "import os\n",
    "import fitz  # PyMuPDF\n",
    "import json\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI  # ‚úÖ New version calling method\n",
    "\n",
    "# ‚úÖ Load API key\n",
    "load_dotenv()\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "\n",
    "client = OpenAI(api_key=api_key)\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b1b6ffbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pdf2image import convert_from_path\n",
    "import pytesseract\n",
    "from PIL import Image\n",
    "import tempfile\n",
    "import os\n",
    "# OCR Recovery Function: Used to extract text from the first and last page images\n",
    "def extract_text_with_ocr(pdf_path, front_n=10, back_n=10, dpi=300):\n",
    "    try:\n",
    "        with tempfile.TemporaryDirectory() as path:\n",
    "            # Convert PDF pages to images\n",
    "            images = convert_from_path(pdf_path, dpi=dpi, output_folder=path)\n",
    "            total_pages = len(images)\n",
    "            selected_pages = []\n",
    "\n",
    "            for i in range(min(front_n, total_pages)):\n",
    "                selected_pages.append(images[i])\n",
    "\n",
    "            for i in range(max(0, total_pages - back_n), total_pages):\n",
    "                selected_pages.append(images[i])\n",
    "\n",
    "            # Extract text using OCR\n",
    "            text_parts = [pytesseract.image_to_string(img) for img in selected_pages]\n",
    "            return \"\\n\".join(text_parts)\n",
    "    except Exception as e:\n",
    "        return f\"OCR ERROR: {e}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "19d888b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_front_back_text(pdf_path, front_n=5, back_n=5):\n",
    "    try:\n",
    "        doc = fitz.open(pdf_path)\n",
    "        texts = []\n",
    "        for i in range(min(front_n, len(doc))):\n",
    "            texts.append(doc[i].get_text())\n",
    "        for i in range(max(0, len(doc) - back_n), len(doc)):\n",
    "            texts.append(doc[i].get_text())\n",
    "        doc.close()\n",
    "        full_text = \"\\n\".join(texts)\n",
    "        if len(full_text.strip()) < 50:\n",
    "            raise ValueError(\"Empty or invalid text, fallback to OCR.\")\n",
    "        return full_text\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è PyMuPDF failed on {pdf_path.name}, switching to OCR...\")\n",
    "        return extract_text_with_ocr(pdf_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "60647d13",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating training data: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 50/50 [13:27<00:00, 16.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ ËÆ≠ÁªÉÊï∞ÊçÆÂ∑≤‰øùÂ≠ò:\n",
      "- JSONL: output/bert_training_data.jsonl\n",
      "- CSV: output/gpt_classification_preview.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>text</th>\n",
       "      <th>reasoning</th>\n",
       "      <th>report_type</th>\n",
       "      <th>has_sustainability_section</th>\n",
       "      <th>sustainability_section_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Unknown_8f57f855-11bb-496d-9916-91ff88cb537b_s...</td>\n",
       "      <td>...</td>\n",
       "      <td>The document is a Form 10-K filed with the U.S...</td>\n",
       "      <td>annual report</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Toyota_Industries_Corp_environment2004_40h96hj...</td>\n",
       "      <td>Social &amp; Environmental Report\\n2004\\n\\nC\\nO\\nN...</td>\n",
       "      <td>The document is titled 'Social &amp; Environmental...</td>\n",
       "      <td>sustainability report</td>\n",
       "      <td>True</td>\n",
       "      <td>Social &amp; Environmental Report 2004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Knoll_Inc_Knoll_Enviro_2008_gqetdkb7.pdf</td>\n",
       "      <td>Knoll and Sustainable Design\\n2008 Environment...</td>\n",
       "      <td>The document is titled '2008 Environmental, He...</td>\n",
       "      <td>sustainability report</td>\n",
       "      <td>True</td>\n",
       "      <td>Environmental, Health &amp; Safety</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Intel_Corp__fwws0wtm.pdf</td>\n",
       "      <td>2010 Corporate Responsibility Report\\n\\nOn the...</td>\n",
       "      <td>The document is titled '2010 Corporate Respons...</td>\n",
       "      <td>sustainability report</td>\n",
       "      <td>True</td>\n",
       "      <td>Environmental Factors, Social Factors, Governa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Unknown_2020_SEBANG20SUSTAINABILITY20REPORT_EN...</td>\n",
       "      <td>This report is printed on FSC¬Æ (Forest Steward...</td>\n",
       "      <td>The document is titled '2020 SEBANG Sustainabi...</td>\n",
       "      <td>sustainability report</td>\n",
       "      <td>True</td>\n",
       "      <td>Sustainable Structure, Our Society, Environmen...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            filename  \\\n",
       "0  Unknown_8f57f855-11bb-496d-9916-91ff88cb537b_s...   \n",
       "1  Toyota_Industries_Corp_environment2004_40h96hj...   \n",
       "2           Knoll_Inc_Knoll_Enviro_2008_gqetdkb7.pdf   \n",
       "3                           Intel_Corp__fwws0wtm.pdf   \n",
       "4  Unknown_2020_SEBANG20SUSTAINABILITY20REPORT_EN...   \n",
       "\n",
       "                                                text  \\\n",
       "0  ¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†...   \n",
       "1  Social & Environmental Report\\n2004\\n\\nC\\nO\\nN...   \n",
       "2  Knoll and Sustainable Design\\n2008 Environment...   \n",
       "3  2010 Corporate Responsibility Report\\n\\nOn the...   \n",
       "4  This report is printed on FSC¬Æ (Forest Steward...   \n",
       "\n",
       "                                           reasoning            report_type  \\\n",
       "0  The document is a Form 10-K filed with the U.S...          annual report   \n",
       "1  The document is titled 'Social & Environmental...  sustainability report   \n",
       "2  The document is titled '2008 Environmental, He...  sustainability report   \n",
       "3  The document is titled '2010 Corporate Respons...  sustainability report   \n",
       "4  The document is titled '2020 SEBANG Sustainabi...  sustainability report   \n",
       "\n",
       "   has_sustainability_section  \\\n",
       "0                       False   \n",
       "1                        True   \n",
       "2                        True   \n",
       "3                        True   \n",
       "4                        True   \n",
       "\n",
       "                         sustainability_section_name  \n",
       "0                                                     \n",
       "1                 Social & Environmental Report 2004  \n",
       "2                     Environmental, Health & Safety  \n",
       "3  Environmental Factors, Social Factors, Governa...  \n",
       "4  Sustainable Structure, Our Society, Environmen...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "label_set = {\"annual report\", \"sustainability report\", \"integrated report\", \"other\"}\n",
    "\n",
    "def classify_with_gpt_v4(text):\n",
    "    prompt = f\"\"\"\n",
    "The following text is extracted from a corporate report (first and last few pages).\n",
    "\n",
    "Your tasks:\n",
    "\n",
    "1. Classify the report into one of the following types:\n",
    "- \"sustainability report\": The document primarily focuses on ESG, sustainability, CSR, or GRI/SDGs-related topics. It does NOT contain full audited financial statements.\n",
    "- \"annual report\": The document primarily contains audited financial disclosures, such as income statements, cash flow statements, balance sheets, and auditor's reports. ESG content, if any, is limited or supplementary.\n",
    "- \"integrated report\": The document includes BOTH complete financial disclosures and structured sustainability content within the same document.\n",
    "- \"other\": The document does not meet the criteria for any of the above (e.g., regulatory compliance reports, environmental approvals, investor brochures, etc.)\n",
    "\n",
    "2. Important judgment rules:\n",
    "- Do NOT classify a \"Corporate Social Responsibility Report\", \"Corporate Responsibility Report\", or \"CSR Report\" as \"integrated report\" unless it also includes full audited financials.\n",
    "- If the title contains \"Annual Report\" but the content lacks actual financial statements, do NOT classify it as \"annual\" or \"integrated\".\n",
    "- References or summaries of financials are NOT sufficient ‚Äî only classify based on complete financial statement inclusion.\n",
    "\n",
    "3. If the document contains a distinct sustainability section (e.g. a chapter on ESG/CSR/GRI/SDGs content that constitutes more than 50% of a section), mark `has_sustainability_section = true`, and extract the section name if available.\n",
    "\n",
    "Return a JSON object with the following fields:\n",
    "{{\n",
    "  \"reasoning\": \"...\",\n",
    "  \"report_type\": \"...\",\n",
    "  \"has_sustainability_section\": true/false,\n",
    "  \"sustainability_section_name\": \"...\"\n",
    "}}\n",
    "\n",
    "Content:\n",
    "{text}\n",
    "\"\"\"\n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-4.1-mini\",  # Or gpt-4.1 when available\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ],\n",
    "            temperature=0\n",
    "        )\n",
    "        reply = response.choices[0].message.content\n",
    "        parsed = json.loads(reply)\n",
    "        return parsed\n",
    "    except Exception as e:\n",
    "        return {\"error\": str(e)}\n",
    "    \n",
    "\n",
    "# ‚úÖ Batch-Generate Training Data\n",
    "def generate_training_data(pdf_folder=\"pdf_folder\", output_jsonl=\"output/bert_training_data.jsonl\", max_files=50):\n",
    "    full_records = []  # Store complete records for CSV\n",
    "    training_records = []  # Store text + label (only includes report_type)\n",
    "\n",
    "    pdf_files = [f for f in os.listdir(pdf_folder) if f.lower().endswith(\".pdf\")]\n",
    "    pdf_files = pdf_files[:max_files]\n",
    "\n",
    "    for fname in tqdm(pdf_files, desc=\"Generating training data\"):\n",
    "        fpath = os.path.join(pdf_folder, fname)\n",
    "        text = extract_front_back_text(fpath)\n",
    "        if text.startswith(\"ERROR\"):\n",
    "            continue\n",
    "\n",
    "        label_info = classify_with_gpt_v4(text)\n",
    "        if \"error\" in label_info:\n",
    "            continue\n",
    "\n",
    "        # ‚úÖ Save two versions\n",
    "        full_records.append({\n",
    "            \"filename\": fname,\n",
    "            \"text\": text,\n",
    "            **label_info  # reasoning, report_type, etc.\n",
    "        })\n",
    "\n",
    "        training_records.append({\n",
    "            \"text\": text,\n",
    "            \"label\": label_info[\"report_type\"]\n",
    "        })\n",
    "\n",
    "    # ‚úÖ Save training JSONL (contains only text + label)\n",
    "    os.makedirs(os.path.dirname(output_jsonl), exist_ok=True)\n",
    "    with open(output_jsonl, \"w\") as f:\n",
    "        for r in training_records:\n",
    "            json.dump(r, f)\n",
    "            f.write(\"\\n\")\n",
    "\n",
    "\n",
    "    df = pd.DataFrame(full_records)\n",
    "    df.to_csv(\"output/gpt_classification_preview.csv\", index=False)\n",
    "\n",
    "    print(f\"‚úÖ ËÆ≠ÁªÉÊï∞ÊçÆÂ∑≤‰øùÂ≠ò:\\n- JSONL: {output_jsonl}\\n- CSV: output/gpt_classification_preview.csv\")\n",
    "\n",
    "    return df\n",
    "\n",
    "df = generate_training_data()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c8b941e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 11.11%\n",
      "‚úÖ Saved to classification_comparison.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/9z/mm8bj8yn2yj6rk7vdlhpt07h0000gn/T/ipykernel_30088/2182635911.py:41: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df_merged_cleaned = df_merged.applymap(clean_illegal_excel_chars)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä detailed \n",
      "\n",
      "                       precision    recall  f1-score   support\n",
      "\n",
      "        annual report      0.667     1.000     0.800         2\n",
      "    integrated report      1.000     0.500     0.667         2\n",
      "                other      1.000     1.000     1.000         1\n",
      "sustainability report      1.000     1.000     1.000         5\n",
      "\n",
      "             accuracy                          0.900        10\n",
      "            macro avg      0.917     0.875     0.867        10\n",
      "         weighted avg      0.933     0.900     0.893        10\n",
      "\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'seaborn'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 66\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28mprint\u001b[39m(report)\n\u001b[1;32m     65\u001b[0m \u001b[38;5;66;03m# === ÂèØËßÜÂåñÊ∑∑Ê∑ÜÁü©ÈòµÔºàÂèØÈÄâÔºâ===\u001b[39;00m\n\u001b[0;32m---> 66\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mseaborn\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msns\u001b[39;00m\n\u001b[1;32m     67\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[1;32m     69\u001b[0m cm \u001b[38;5;241m=\u001b[39m confusion_matrix(valid[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreport_type_human\u001b[39m\u001b[38;5;124m\"\u001b[39m], valid[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreport_type_gpt\u001b[39m\u001b[38;5;124m\"\u001b[39m], labels\u001b[38;5;241m=\u001b[39mvalid[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreport_type_human\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39munique())\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'seaborn'"
     ]
    }
   ],
   "source": [
    "# output/comb_results.csv\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# ==== 1. Set File Path ====\n",
    "human_label_path = \"check/pdf_classification.xlsx\"\n",
    "gpt_result_path = \"output/gpt_classification_preview.csv\"\n",
    "df_human = pd.read_excel(human_label_path)\n",
    "df_gpt = pd.read_csv(gpt_result_path)\n",
    "\n",
    "# ==3. Standardize column names to ensure filename and report_type exist\n",
    "df_human.columns = [col.strip().lower() for col in df_human.columns]\n",
    "df_gpt.columns = [col.strip().lower() for col in df_gpt.columns]\n",
    "\n",
    "# ===4. Merge two tables\n",
    "df_merged = pd.merge(df_human, df_gpt, left_on=\"file_name\",\n",
    "    right_on=\"filename\",\n",
    "    how=\"left\")\n",
    "df_merged = df_merged.drop_duplicates(subset=\"file_name\", keep=\"first\")\n",
    "\n",
    "# ==== 6. Compare two classification results ====\n",
    "df_merged[\"report_type_human\"] = df_merged[\"report_type_human\"].str.strip().str.lower()\n",
    "df_merged[\"report_type_gpt\"] = df_merged[\"report_type\"].str.strip().str.lower()\n",
    "df_merged[\"is_correct\"] = df_merged[\"report_type_human\"] == df_merged[\"report_type_gpt\"]\n",
    "\n",
    "# ===7. Calculate the accuracy rate==\n",
    "accuracy = df_merged[\"is_correct\"].mean()\n",
    "print(f\"accuracy: {accuracy:.2%}\")\n",
    "\n",
    "\n",
    "import re\n",
    "\n",
    "def clean_illegal_excel_chars(text):\n",
    "    if isinstance(text, str):\n",
    "        return re.sub(r\"[\\x00-\\x1F\\x7F]\", \"\", text)\n",
    "    return text\n",
    "\n",
    "# Remove invalid characters\n",
    "df_merged_cleaned = df_merged.applymap(clean_illegal_excel_chars)\n",
    "\n",
    "\n",
    "df_merged_cleaned.to_excel(\"pipeline_eval/7/classification_comparison.xlsx\", index=False)\n",
    "print(\"‚úÖ Saved to classification_comparison.xlsx\")\n",
    "# df_merged.to_excel(\"pipeline_eval/7/classification_comparison.xlsx\", index=False)\n",
    "# print(\"saved to classification_comparison_result.xlsx\")\n",
    "\n",
    "import sklearn\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# === ‰ªÖ‰øùÁïôÈùûÁ©∫ÂØπÊØîÈ°πÔºàÈò≤Ê≠¢Á©∫ÂÄºÂΩ±ÂìçÔºâ===\n",
    "valid = df_merged[~df_merged[\"report_type_human\"].isna() & ~df_merged[\"report_type_gpt\"].isna()]\n",
    "\n",
    "# === ÊâìÂç∞ classification report ===\n",
    "report = classification_report(\n",
    "    valid[\"report_type_human\"], \n",
    "    valid[\"report_type_gpt\"], \n",
    "    digits=3, \n",
    "    output_dict=False  # Êîπ‰∏∫ True ÂèØËøîÂõûÂ≠óÂÖ∏\n",
    ")\n",
    "print(\"üìä detailed \\n\")\n",
    "print(report)\n",
    "\n",
    "# === ÂèØËßÜÂåñÊ∑∑Ê∑ÜÁü©ÈòµÔºàÂèØÈÄâÔºâ===\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "cm = confusion_matrix(valid[\"report_type_human\"], valid[\"report_type_gpt\"], labels=valid[\"report_type_human\"].unique())\n",
    "plt.figure(figsize=(6,5))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=valid[\"report_type_human\"].unique(),\n",
    "            yticklabels=valid[\"report_type_human\"].unique())\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"True\")\n",
    "plt.title(\"Confusion Matrix- Classification Comparison\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5cabbbd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ÂáÜÂ§áËÆ≠ÁªÉÊï∞ÊçÆ...\n",
      "Ê†áÁ≠æÂàÜÂ∏É:\n",
      "label\n",
      "sustainability report    29\n",
      "annual report             8\n",
      "integrated report         7\n",
      "other                     3\n",
      "Name: count, dtype: int64\n",
      "ËÆ≠ÁªÉÊ®°Âûã...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Epoch 1/4: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:36<00:00,  7.31s/it, loss=1.21]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Average Loss: 1.4021\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/4: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:34<00:00,  6.91s/it, loss=1.19] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Average Loss: 1.1812\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/4: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:34<00:00,  6.86s/it, loss=0.9]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Average Loss: 1.1299\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/4: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:40<00:00,  8.14s/it, loss=1.02]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, Average Loss: 1.1007\n",
      "ÂàÜÁ±ªÊä•Âëä:\n",
      "                       precision    recall  f1-score   support\n",
      "\n",
      "        annual report       0.00      0.00      0.00         2\n",
      "    integrated report       0.00      0.00      0.00         1\n",
      "                other       0.00      0.00      0.00         1\n",
      "sustainability report       0.60      1.00      0.75         6\n",
      "\n",
      "             accuracy                           0.60        10\n",
      "            macro avg       0.15      0.25      0.19        10\n",
      "         weighted avg       0.36      0.60      0.45        10\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniconda/base/envs/transformers_env/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/Caskroom/miniconda/base/envs/transformers_env/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/Caskroom/miniconda/base/envs/transformers_env/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ÈÉ®ÁΩ≤Ê®°Âûã...\n",
      "ÊµãËØïÂàÜÁ±ª: ('sustainability report', 0.416676789522171)\n",
      "‰ΩøÁî®ËÆ≠ÁªÉÂ•ΩÁöÑÊ®°ÂûãÂàÜÁ±ªPDF (Ââç100‰∏™)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ÂàÜÁ±ªPDFÊñá‰ª∂ (ÊúÄÂ§ö1500‰∏™):  20%|‚ñà‚ñà        | 256/1278 [01:36<04:31,  3.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MuPDF error: format error: cmsOpenProfileFromMem failed\n",
      "\n",
      "MuPDF error: format error: cmsOpenProfileFromMem failed\n",
      "\n",
      "MuPDF error: format error: cmsOpenProfileFromMem failed\n",
      "\n",
      "MuPDF error: format error: cmsOpenProfileFromMem failed\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ÂàÜÁ±ªPDFÊñá‰ª∂ (ÊúÄÂ§ö1500‰∏™):  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 725/1278 [03:58<02:41,  3.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MuPDF error: format error: object is not a stream\n",
      "\n",
      "MuPDF error: format error: object is not a stream\n",
      "\n",
      "MuPDF error: format error: object is not a stream\n",
      "\n",
      "MuPDF error: format error: object is not a stream\n",
      "\n",
      "MuPDF error: format error: object is not a stream\n",
      "\n",
      "MuPDF error: format error: object is not a stream\n",
      "\n",
      "MuPDF error: format error: object is not a stream\n",
      "\n",
      "MuPDF error: format error: object is not a stream\n",
      "\n",
      "MuPDF error: format error: object is not a stream\n",
      "\n",
      "MuPDF error: format error: object is not a stream\n",
      "\n",
      "MuPDF error: format error: object is not a stream\n",
      "\n",
      "MuPDF error: format error: object is not a stream\n",
      "\n",
      "MuPDF error: format error: object is not a stream\n",
      "\n",
      "MuPDF error: format error: object is not a stream\n",
      "\n",
      "MuPDF error: format error: object is not a stream\n",
      "\n",
      "MuPDF error: format error: object is not a stream\n",
      "\n",
      "MuPDF error: format error: object is not a stream\n",
      "\n",
      "MuPDF error: format error: object is not a stream\n",
      "\n",
      "MuPDF error: format error: object is not a stream\n",
      "\n",
      "MuPDF error: format error: object is not a stream\n",
      "\n",
      "MuPDF error: format error: object is not a stream\n",
      "\n",
      "MuPDF error: format error: object is not a stream\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ÂàÜÁ±ªPDFÊñá‰ª∂ (ÊúÄÂ§ö1500‰∏™):  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 1150/1278 [22:56<00:34,  3.66it/s]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MuPDF error: format error: cmsOpenProfileFromMem failed\n",
      "\n",
      "MuPDF error: format error: cmsOpenProfileFromMem failed\n",
      "\n",
      "MuPDF error: format error: cmsOpenProfileFromMem failed\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ÂàÜÁ±ªPDFÊñá‰ª∂ (ÊúÄÂ§ö1500‰∏™):  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 1169/1278 [23:01<00:25,  4.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MuPDF error: format error: No default Layer config\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ÂàÜÁ±ªPDFÊñá‰ª∂ (ÊúÄÂ§ö1500‰∏™): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1278/1278 [23:29<00:00,  1.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ÁªìÊûúÂ∑≤‰øùÂ≠òÂà∞: output/local_classification_results.csv\n",
      "ÊµÅÁ®ãÂÆåÊàê!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Dataset as TorchDataset\n",
    "from torch.optim import AdamW  # Import AdamW from torch.optim\n",
    "from transformers import (\n",
    "    AutoTokenizer, \n",
    "    AutoModelForSequenceClassification,\n",
    "    get_linear_schedule_with_warmup\n",
    ")\n",
    "from datasets import Dataset, load_dataset\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "import os\n",
    "os.environ['HF_ENDPOINT'] = 'https://hf-mirror.com'\n",
    "\n",
    "# ========== 1. Data Preprocessing and Preparation ==========\n",
    "def prepare_training_data(jsonl_file, test_size=0.2, random_state=42):\n",
    "    \"\"\"\n",
    "    Prepare training data, including loading, splitting, and label encoding\n",
    "    \"\"\"\n",
    "    # Load JSONL data\n",
    "    data = []\n",
    "    with open(jsonl_file, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            data.append(json.loads(line))\n",
    "    \n",
    "    # Convert to DataFrame\n",
    "    df = pd.DataFrame(data)\n",
    "    \n",
    "    # Check label distribution\n",
    "    print(\"Label distribution:\")\n",
    "    print(df['label'].value_counts())\n",
    "    \n",
    "    # Create label mapping\n",
    "    label_list = sorted(df['label'].unique())\n",
    "    label2id = {label: idx for idx, label in enumerate(label_list)}\n",
    "    id2label = {idx: label for label, idx in label2id.items()}\n",
    "    \n",
    "    # Add numeric labels\n",
    "    df['label_id'] = df['label'].map(label2id)\n",
    "    \n",
    "    # Split train and test set\n",
    "    train_df, test_df = train_test_split(\n",
    "        df, test_size=test_size, random_state=random_state, stratify=df['label_id']\n",
    "    )\n",
    "    \n",
    "    return train_df, test_df, label2id, id2label\n",
    "\n",
    "# ========== 2. Custom Dataset Class ==========\n",
    "class ReportDataset(TorchDataset):\n",
    "    def __init__(self, texts, labels, tokenizer, max_length=512):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        text = str(self.texts[idx])\n",
    "        label = self.labels[idx]\n",
    "        \n",
    "        encoding = self.tokenizer(\n",
    "            text,\n",
    "            truncation=True,\n",
    "            padding='max_length',\n",
    "            max_length=self.max_length,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        \n",
    "        return {\n",
    "            'input_ids': encoding['input_ids'].flatten(),\n",
    "            'attention_mask': encoding['attention_mask'].flatten(),\n",
    "            'labels': torch.tensor(label, dtype=torch.long)\n",
    "        }\n",
    "\n",
    "# ========== 3. Simplified Model Training ==========\n",
    "def simple_train_model(train_df, test_df, label2id, id2label, \n",
    "                      model_name=\"bert-base-uncased\", output_dir=\"./fine_tuned_model\"):\n",
    "    \"\"\"\n",
    "    Train model using simplified method\n",
    "    \"\"\"\n",
    "    # Load tokenizer and model\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(\n",
    "        \"bert-base-uncased\", \n",
    "        num_labels=len(label2id),\n",
    "        id2label=id2label,\n",
    "        label2id=label2id\n",
    "    )\n",
    "    \n",
    "    # Create dataset\n",
    "    train_dataset = ReportDataset(\n",
    "        train_df['text'].tolist(),\n",
    "        train_df['label_id'].tolist(),\n",
    "        tokenizer\n",
    "    )\n",
    "    \n",
    "    test_dataset = ReportDataset(\n",
    "        test_df['text'].tolist(),\n",
    "        test_df['label_id'].tolist(),\n",
    "        tokenizer\n",
    "    )\n",
    "    \n",
    "    # Create dataloader\n",
    "    train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=8, shuffle=False)\n",
    "    \n",
    "    # Set device\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "    \n",
    "    # Set optimizer and scheduler\n",
    "    optimizer = AdamW(model.parameters(), lr=2e-5)\n",
    "    total_steps = len(train_loader) * 4  # 4 epochs\n",
    "    scheduler = get_linear_schedule_with_warmup(\n",
    "        optimizer,\n",
    "        num_warmup_steps=0,\n",
    "        num_training_steps=total_steps\n",
    "    )\n",
    "    \n",
    "    # Training loop\n",
    "    model.train()\n",
    "    for epoch in range(4):\n",
    "        total_loss = 0\n",
    "        progress_bar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/4\")\n",
    "        \n",
    "        for batch in progress_bar:\n",
    "            # Move to device\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = model(\n",
    "                input_ids=input_ids,\n",
    "                attention_mask=attention_mask,\n",
    "                labels=labels\n",
    "            )\n",
    "            \n",
    "            loss = outputs.loss\n",
    "            \n",
    "            # Backward pass\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "            progress_bar.set_postfix({'loss': loss.item()})\n",
    "        \n",
    "        avg_loss = total_loss / len(train_loader)\n",
    "        print(f\"Epoch {epoch+1}, Average Loss: {avg_loss:.4f}\")\n",
    "    \n",
    "    # Evaluate model\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    true_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in test_loader:\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "            \n",
    "            outputs = model(\n",
    "                input_ids=input_ids,\n",
    "                attention_mask=attention_mask\n",
    "            )\n",
    "            \n",
    "            _, preds = torch.max(outputs.logits, dim=1)\n",
    "            \n",
    "            predictions.extend(preds.cpu().tolist())\n",
    "            true_labels.extend(labels.cpu().tolist())\n",
    "    \n",
    "    # Calculate evaluation metrics - fix class mismatch issue\n",
    "    print(\"Classification report:\")\n",
    "    \n",
    "    # Get actual labels\n",
    "    unique_labels = np.unique(true_labels + predictions)\n",
    "    \n",
    "    # Create corresponding label names\n",
    "    target_names = [id2label[label_id] for label_id in sorted(unique_labels)]\n",
    "    \n",
    "    # Generate classification report\n",
    "    print(classification_report(true_labels, predictions, target_names=target_names, labels=sorted(unique_labels)))\n",
    "    \n",
    "    # Save model\n",
    "    model.save_pretrained(output_dir)\n",
    "    tokenizer.save_pretrained(output_dir)\n",
    "    \n",
    "    return model, tokenizer\n",
    "\n",
    "# ========== 4. PDF Text Extraction Function ==========\n",
    "def extract_text_from_pdf(pdf_path, front_n=5, back_n=5):\n",
    "    \"\"\"\n",
    "    Extract text from the first and last few pages of a PDF file\n",
    "    \"\"\"\n",
    "    try:\n",
    "        import fitz  # PyMuPDF\n",
    "        doc = fitz.open(pdf_path)\n",
    "        total = len(doc)\n",
    "        text = \"\"\n",
    "        for i in range(min(front_n, total)):\n",
    "            text += doc[i].get_text()\n",
    "        for i in range(max(0, total - back_n), total):\n",
    "            text += doc[i].get_text()\n",
    "        return text.strip()\n",
    "    except Exception as e:\n",
    "        return f\"ERROR extracting {pdf_path}: {e}\"\n",
    "\n",
    "# ========== 5. Local Classifier Deployment ==========\n",
    "class ReportClassifier:\n",
    "    def __init__(self, model_path):\n",
    "        \"\"\"\n",
    "        Load trained model and tokenizer\n",
    "        \"\"\"\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "        self.model = AutoModelForSequenceClassification.from_pretrained(model_path)\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.model.to(self.device)\n",
    "        self.model.eval()\n",
    "        \n",
    "        # Get label mapping\n",
    "        self.id2label = self.model.config.id2label\n",
    "        self.label2id = self.model.config.label2id\n",
    "    \n",
    "    def classify(self, text, return_confidence=False):\n",
    "        \"\"\"\n",
    "        Classify a single text\n",
    "        \"\"\"\n",
    "        # Preprocess text\n",
    "        inputs = self.tokenizer(\n",
    "            text, \n",
    "            return_tensors=\"pt\", \n",
    "            truncation=True, \n",
    "            padding=True, \n",
    "            max_length=512\n",
    "        )\n",
    "        \n",
    "        # Move to device\n",
    "        inputs = {k: v.to(self.device) for k, v in inputs.items()}\n",
    "        \n",
    "        # Prediction\n",
    "        with torch.no_grad():\n",
    "            outputs = self.model(**inputs)\n",
    "        \n",
    "        # Get prediction result\n",
    "        probs = torch.nn.functional.softmax(outputs.logits, dim=-1)\n",
    "        pred_id = torch.argmax(probs, dim=1).item()\n",
    "        confidence = probs[0][pred_id].item()\n",
    "        label = self.id2label[pred_id]\n",
    "        \n",
    "        if return_confidence:\n",
    "            return label, confidence\n",
    "        return label\n",
    "    \n",
    "    def classify_pdf(self, pdf_path, front_n=5, back_n=5):\n",
    "        \"\"\"\n",
    "        Directly classify a PDF file\n",
    "        \"\"\"\n",
    "        # Extract text\n",
    "        text = extract_text_from_pdf(pdf_path, front_n, back_n)\n",
    "        \n",
    "        # Classification\n",
    "        label, confidence = self.classify(text, return_confidence=True)\n",
    "        \n",
    "        return {\n",
    "            \"filename\": os.path.basename(pdf_path),\n",
    "            \"label\": label,\n",
    "            \"confidence\": confidence,\n",
    "            \"text_preview\": text[:500] + \"...\" if len(text) > 500 else text\n",
    "        }\n",
    "    \n",
    "    def batch_classify_pdfs(self, pdf_folder, output_csv=\"output/local_classification_results.csv\", max_files=100):\n",
    "        \"\"\"\n",
    "        Batch classify PDF files in a folder, up to max_files files\n",
    "        \"\"\"\n",
    "        pdf_files = [f for f in os.listdir(pdf_folder) if f.lower().endswith(\".pdf\")]\n",
    "        \n",
    "        # Only process the first max_files files\n",
    "        pdf_files = pdf_files[:max_files]\n",
    "        \n",
    "        results = []\n",
    "        for fname in tqdm(pdf_files, desc=f\"Classifying PDF files (up to {max_files})\"):\n",
    "            fpath = os.path.join(pdf_folder, fname)\n",
    "            result = self.classify_pdf(fpath)\n",
    "            results.append(result)\n",
    "        \n",
    "        # Save results\n",
    "        df = pd.DataFrame(results)\n",
    "        df.to_csv(output_csv, index=False)\n",
    "        print(f\"Results saved to: {output_csv}\")\n",
    "        \n",
    "        return df\n",
    "\n",
    "# ========== 6. Complete Training and Deployment Pipeline ==========\n",
    "def train_and_deploy_pipeline(jsonl_path, model_output_dir=\"./fine_tuned_model\"):\n",
    "    \"\"\"\n",
    "    Complete training and deployment pipeline\n",
    "    \"\"\"\n",
    "    # 1. Prepare data\n",
    "    print(\"Preparing training data...\")\n",
    "    train_df, test_df, label2id, id2label = prepare_training_data(jsonl_path)\n",
    "    \n",
    "    # 2. Train model\n",
    "    print(\"Training model...\")\n",
    "    model, tokenizer = simple_train_model(\n",
    "        train_df, test_df, label2id, id2label, output_dir=model_output_dir\n",
    "    )\n",
    "    \n",
    "    # 3. Deploy model\n",
    "    print(\"Deploying model...\")\n",
    "    classifier = ReportClassifier(model_output_dir)\n",
    "    \n",
    "    # Test classifier\n",
    "    test_text = \"This is a sample annual report with financial statements and auditor's report.\"\n",
    "    result = classifier.classify(test_text, return_confidence=True)\n",
    "    print(f\"Test classification: {result}\")\n",
    "    \n",
    "    return classifier\n",
    "\n",
    "# ========== 7. Main Execution Function ==========\n",
    "if __name__ == \"__main__\":\n",
    "    # Set paths\n",
    "    jsonl_path = \"/Users/zhangjingyu/Desktop/ËØæ‰ª∂/IRP/starting/output/bert_training_data.jsonl\"\n",
    "    model_dir = \"./fine_tuned_report_classifier\"\n",
    "    pdf_folder = \"pdf_folder\"  \n",
    "    \n",
    "    # Ensure output directory exists\n",
    "    os.makedirs(model_dir, exist_ok=True)\n",
    "    os.makedirs(\"output\", exist_ok=True)\n",
    "    \n",
    "    # Execute full pipeline\n",
    "    classifier = train_and_deploy_pipeline(jsonl_path, model_dir)\n",
    "    \n",
    "    # Use trained model to batch classify PDFs, process first 100 files\n",
    "    print(\"Classifying PDFs with trained model (first 100)...\")\n",
    "    results_df = classifier.batch_classify_pdfs(pdf_folder, max_files=1500)\n",
    "    \n",
    "    print(\"Pipeline completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bc74c22d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openpyxl in /opt/homebrew/Caskroom/miniconda/base/envs/transformers_env/lib/python3.9/site-packages (3.1.5)\n",
      "Requirement already satisfied: et-xmlfile in /opt/homebrew/Caskroom/miniconda/base/envs/transformers_env/lib/python3.9/site-packages (from openpyxl) (2.0.0)\n",
      "accuracy: 51.85%\n",
      "‚úÖ Saved to classification_comparison.xlsx\n",
      "üìä detailed \n",
      "\n",
      "                       precision    recall  f1-score   support\n",
      "\n",
      "        annual report      0.000     0.000     0.000         7\n",
      "    integrated report      0.000     0.000     0.000        16\n",
      "                other      0.000     0.000     0.000         2\n",
      "sustainability report      0.627     1.000     0.771        42\n",
      "\n",
      "             accuracy                          0.627        67\n",
      "            macro avg      0.157     0.250     0.193        67\n",
      "         weighted avg      0.393     0.627     0.483        67\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/9z/mm8bj8yn2yj6rk7vdlhpt07h0000gn/T/ipykernel_30088/843036758.py:41: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df_merged_cleaned = df_merged.applymap(clean_illegal_excel_chars)\n",
      "/opt/homebrew/Caskroom/miniconda/base/envs/transformers_env/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/Caskroom/miniconda/base/envs/transformers_env/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/Caskroom/miniconda/base/envs/transformers_env/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'seaborn'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 66\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28mprint\u001b[39m(report)\n\u001b[1;32m     65\u001b[0m \u001b[38;5;66;03m# === ÂèØËßÜÂåñÊ∑∑Ê∑ÜÁü©ÈòµÔºàÂèØÈÄâÔºâ===\u001b[39;00m\n\u001b[0;32m---> 66\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mseaborn\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msns\u001b[39;00m\n\u001b[1;32m     67\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[1;32m     69\u001b[0m cm \u001b[38;5;241m=\u001b[39m confusion_matrix(valid[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreport_type_human\u001b[39m\u001b[38;5;124m\"\u001b[39m], valid[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreport_type_gpt\u001b[39m\u001b[38;5;124m\"\u001b[39m], labels\u001b[38;5;241m=\u001b[39mvalid[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreport_type_human\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39munique())\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'seaborn'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "!pip install openpyxl\n",
    "\n",
    "# ==== 1. Set file paths ====\n",
    "human_label_path = \"check/pdf_classification.xlsx\"\n",
    "gpt_result_path = \"output/local_classification_results.csv\"\n",
    "\n",
    "# ==== 2. Read files ====\n",
    "df_human = pd.read_excel(human_label_path)\n",
    "df_gpt = pd.read_csv(gpt_result_path)\n",
    "\n",
    "# ==== 3. Normalize column names, ensure filename and report_type exist ====\n",
    "df_human.columns = [col.strip().lower() for col in df_human.columns]\n",
    "df_gpt.columns = [col.strip().lower() for col in df_gpt.columns]\n",
    "\n",
    "# ==== 4. Merge two tables ====\n",
    "df_merged = pd.merge(df_human, df_gpt, left_on=\"file_name\",\n",
    "    right_on=\"filename\",\n",
    "    how=\"left\")\n",
    "df_merged = df_merged.drop_duplicates(subset=\"file_name\", keep=\"first\")\n",
    "\n",
    "# ==== 6. Compare two classification results ====\n",
    "df_merged[\"report_type_human\"] = df_merged[\"report_type_human\"].str.strip().str.lower()\n",
    "df_merged[\"report_type_gpt\"] = df_merged[\"label\"].str.strip().str.lower()\n",
    "df_merged[\"is_correct\"] = df_merged[\"report_type_human\"] == df_merged[\"report_type_gpt\"]\n",
    "\n",
    "# ==== 7. Calculate accuracy ====\n",
    "accuracy = df_merged[\"is_correct\"].mean()\n",
    "print(f\"accuracy: {accuracy:.2%}\")\n",
    "\n",
    "# ==== 8. Export comparison results (optional) ====\n",
    "import re\n",
    "\n",
    "def clean_illegal_excel_chars(text):\n",
    "    if isinstance(text, str):\n",
    "        return re.sub(r\"[\\x00-\\x1F\\x7F]\", \"\", text)\n",
    "    return text\n",
    "\n",
    "# Clean illegal characters\n",
    "df_merged_cleaned = df_merged.applymap(clean_illegal_excel_chars)\n",
    "\n",
    "# Export again\n",
    "# df_merged_cleaned.to_excel(\"pipeline_eval/7/classification_comparison.xlsx\", index=False)\n",
    "print(\"‚úÖ Saved to classification_comparison.xlsx\")\n",
    "# df_merged.to_excel(\"pipeline_eval/7/classification_comparison.xlsx\", index=False)\n",
    "# print(\"saved to classification_comparison_result.xlsx\")\n",
    "\n",
    "import sklearn\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# === Only keep non-empty comparison items (to avoid influence of null values) ===\n",
    "valid = df_merged[~df_merged[\"report_type_human\"].isna() & ~df_merged[\"report_type_gpt\"].isna()]\n",
    "\n",
    "# === Print classification report ===\n",
    "report = classification_report(\n",
    "    valid[\"report_type_human\"], \n",
    "    valid[\"report_type_gpt\"], \n",
    "    digits=3, \n",
    "    output_dict=False  # Set to True to return dict\n",
    ")\n",
    "print(\"üìä detailed \\n\")\n",
    "print(report)\n",
    "\n",
    "# === Visualize confusion matrix (optional) ===\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "cm = confusion_matrix(valid[\"report_type_human\"], valid[\"report_type_gpt\"], labels=valid[\"report_type_human\"].unique())\n",
    "plt.figure(figsize=(6,5))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=valid[\"report_type_human\"].unique(),\n",
    "            yticklabels=valid[\"report_type_human\"].unique())\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"True\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b1f6443",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "transformers_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
