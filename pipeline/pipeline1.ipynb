{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aad163bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "üîç Processing PDFs:   0%|          | 5/1277 [03:32<15:01:14, 42.51s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 217\u001b[39m\n\u001b[32m    215\u001b[39m pdf_files = \u001b[38;5;28mlist\u001b[39m(pdf_dir.glob(\u001b[33m\"\u001b[39m\u001b[33m*.pdf\u001b[39m\u001b[33m\"\u001b[39m))\n\u001b[32m    216\u001b[39m \u001b[38;5;66;03m# ‚úÖ ‰∏≤Ë°åÊâßË°åÔºåÈÅøÂÖçÂ§öËøõÁ®ãÂ∫èÂàóÂåñÈóÆÈ¢ò\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m217\u001b[39m results = [\u001b[43mprocess_pdf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpdf\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m pdf \u001b[38;5;129;01min\u001b[39;00m tqdm(pdf_files, desc=\u001b[33m\"\u001b[39m\u001b[33müîç Processing PDFs\u001b[39m\u001b[33m\"\u001b[39m)]\n\u001b[32m    218\u001b[39m df = pd.DataFrame(results)\n\u001b[32m    219\u001b[39m df.to_csv(output_path, index=\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 192\u001b[39m, in \u001b[36mprocess_pdf\u001b[39m\u001b[34m(pdf_path)\u001b[39m\n\u001b[32m    189\u001b[39m text = extract_front_back_text(pdf_path)\n\u001b[32m    191\u001b[39m rtype = classify_report_type(text)\n\u001b[32m--> \u001b[39m\u001b[32m192\u001b[39m year = \u001b[43mextract_report_year\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpdf_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    193\u001b[39m company = extract_company_info(text)\n\u001b[32m    195\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[32m    196\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mfilename\u001b[39m\u001b[33m\"\u001b[39m: pdf_path.name,\n\u001b[32m    197\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mreport_type\u001b[39m\u001b[33m\"\u001b[39m: rtype.get(\u001b[33m\"\u001b[39m\u001b[33mreport_type\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m   (...)\u001b[39m\u001b[32m    207\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mreasoning\u001b[39m\u001b[33m\"\u001b[39m: company.get(\u001b[33m\"\u001b[39m\u001b[33mreasoning\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    208\u001b[39m }\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 137\u001b[39m, in \u001b[36mextract_report_year\u001b[39m\u001b[34m(pdf_path)\u001b[39m\n\u001b[32m    135\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[32m    136\u001b[39m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m137\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mextract_year_from_vision\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpdf_path\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 104\u001b[39m, in \u001b[36mextract_year_from_vision\u001b[39m\u001b[34m(pdf_path, max_pages)\u001b[39m\n\u001b[32m    102\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mextract_year_from_vision\u001b[39m(pdf_path, max_pages=\u001b[32m3\u001b[39m):\n\u001b[32m    103\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m104\u001b[39m         images = \u001b[43mconvert_from_path\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpdf_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdpi\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m200\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpoppler_path\u001b[49m\u001b[43m=\u001b[49m\u001b[43mPOPPLER_PATH\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    105\u001b[39m         \u001b[38;5;28;01mfor\u001b[39;00m i, img \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(images[:max_pages]):\n\u001b[32m    106\u001b[39m             b64 = encode_image_to_base64(img)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Caskroom/miniconda/base/envs/irp_pdf/lib/python3.12/site-packages/pdf2image/pdf2image.py:269\u001b[39m, in \u001b[36mconvert_from_path\u001b[39m\u001b[34m(pdf_path, dpi, output_folder, first_page, last_page, fmt, jpegopt, thread_count, userpw, ownerpw, use_cropbox, strict, transparent, single_file, output_file, poppler_path, grayscale, size, paths_only, use_pdftocairo, timeout, hide_annotations)\u001b[39m\n\u001b[32m    261\u001b[39m             images += _load_from_output_folder(\n\u001b[32m    262\u001b[39m                 output_folder,\n\u001b[32m    263\u001b[39m                 uid,\n\u001b[32m   (...)\u001b[39m\u001b[32m    266\u001b[39m                 in_memory=auto_temp_dir,\n\u001b[32m    267\u001b[39m             )\n\u001b[32m    268\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m269\u001b[39m             images += \u001b[43mparse_buffer_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    270\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    271\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m auto_temp_dir:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Caskroom/miniconda/base/envs/irp_pdf/lib/python3.12/site-packages/pdf2image/parsers.py:28\u001b[39m, in \u001b[36mparse_buffer_to_ppm\u001b[39m\u001b[34m(data)\u001b[39m\n\u001b[32m     26\u001b[39m     size_x, size_y = \u001b[38;5;28mtuple\u001b[39m(size.split(\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m \u001b[39m\u001b[33m\"\u001b[39m))\n\u001b[32m     27\u001b[39m     file_size = \u001b[38;5;28mlen\u001b[39m(code) + \u001b[38;5;28mlen\u001b[39m(size) + \u001b[38;5;28mlen\u001b[39m(rgb) + \u001b[32m3\u001b[39m + \u001b[38;5;28mint\u001b[39m(size_x) * \u001b[38;5;28mint\u001b[39m(size_y) * \u001b[32m3\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m28\u001b[39m     images.append(Image.open(\u001b[43mBytesIO\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[43mfile_size\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m))\n\u001b[32m     29\u001b[39m     index += file_size\n\u001b[32m     31\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m images\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import fitz\n",
    "import pytesseract\n",
    "import tempfile\n",
    "import base64\n",
    "import json\n",
    "import shutil\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "from pdf2image import convert_from_path\n",
    "from dotenv import load_dotenv\n",
    "from tqdm import tqdm\n",
    "from joblib import Parallel, delayed\n",
    "from openai import OpenAI\n",
    "\n",
    "# ‚úÖ Âä†ËΩΩ OpenAI\n",
    "load_dotenv()\n",
    "client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "\n",
    "# ‚úÖ ËÆæÁΩÆ poppler Ë∑ØÂæÑÔºàmacOSÔºâ\n",
    "POPPLER_PATH = \"/opt/homebrew/bin\" if shutil.which(\"pdftoppm\") is None else None\n",
    "\n",
    "# ‚úÖ ÈÄöÁî®ÊñáÊú¨ÊèêÂèñÔºàPyMuPDF + OCR fallbackÔºâ\n",
    "def extract_front_back_text(pdf_path, front_n=5, back_n=5, dpi=300):\n",
    "    try:\n",
    "        doc = fitz.open(pdf_path)\n",
    "        texts = [doc[i].get_text() for i in range(min(front_n, len(doc)))]\n",
    "        texts += [doc[i].get_text() for i in range(max(0, len(doc) - back_n), len(doc))]\n",
    "        doc.close()\n",
    "        text = \"\\n\".join(texts)\n",
    "        if len(text.strip()) < 50:\n",
    "            raise ValueError(\"Too little text\")\n",
    "        return text\n",
    "    except:\n",
    "        with tempfile.TemporaryDirectory() as path:\n",
    "            images = convert_from_path(pdf_path, dpi=dpi, output_folder=path, poppler_path=POPPLER_PATH)\n",
    "            selected = images[:front_n] + images[-back_n:]\n",
    "            return \"\\n\".join([pytesseract.image_to_string(img) for img in selected])\n",
    "\n",
    "# ‚úÖ ‰ªªÂä°1ÔºöÊä•ÂëäÁ±ªÂûãÂàÜÁ±ª\n",
    "def classify_report_type(text):\n",
    "    prompt = f\"\"\"\n",
    "From the text (first/last pages of a corporate report), perform:\n",
    "\n",
    "1. Classify as:\n",
    "- \"sustainability report\"\n",
    "- \"annual report\"\n",
    "- \"integrated report\"\n",
    "- \"other\"\n",
    "\n",
    "2. Check if a sustainability section is included, and name it.\n",
    "\n",
    "Return JSON:\n",
    "{{\n",
    "  \"report_type\": \"...\",\n",
    "  \"has_sustainability_section\": true/false,\n",
    "  \"sustainability_section_name\": \"...\",\n",
    "  \"reasoning\": \"...\"\n",
    "}}\n",
    "\n",
    "Text:\n",
    "{text}\n",
    "\"\"\"\n",
    "    try:\n",
    "        res = client.chat.completions.create(\n",
    "            model=\"gpt-4.1-mini\",\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "        )\n",
    "        return json.loads(res.choices[0].message.content)\n",
    "    except Exception as e:\n",
    "        return {\n",
    "            \"report_type\": \"ERROR\",\n",
    "            \"has_sustainability_section\": \"\",\n",
    "            \"sustainability_section_name\": \"\",\n",
    "            \"reasoning\": str(e)\n",
    "        }\n",
    "\n",
    "# ‚úÖ ‰ªªÂä°2ÔºöÊä•ÂëäÂπ¥Â∫¶ÊèêÂèñÔºàÊñáÊú¨‰ºòÂÖàÔºâ\n",
    "def build_year_prompt(text):\n",
    "    return f\"\"\"\n",
    "Extract any fiscal/reporting year expressions like:\n",
    "- \"FY2023\", \"April 2022 ‚Äì March 2023\", \"for the year ended 31 Dec 2022\"\n",
    "\n",
    "Return JSON:\n",
    "{{\n",
    "  \"normalized_report_year\": \"...\",\n",
    "  \"original_expression\": \"...\",\n",
    "  \"source\": \"...\"\n",
    "}}\n",
    "\n",
    "Text:\n",
    "{text}\n",
    "\"\"\"\n",
    "\n",
    "def encode_image_to_base64(pil_img):\n",
    "    with tempfile.NamedTemporaryFile(suffix=\".png\") as f:\n",
    "        pil_img.save(f.name, format=\"PNG\")\n",
    "        with open(f.name, \"rb\") as img_f:\n",
    "            return base64.b64encode(img_f.read()).decode(\"utf-8\")\n",
    "\n",
    "def extract_year_from_vision(pdf_path, max_pages=3):\n",
    "    try:\n",
    "        images = convert_from_path(pdf_path, dpi=200, poppler_path=POPPLER_PATH)\n",
    "        for i, img in enumerate(images[:max_pages]):\n",
    "            b64 = encode_image_to_base64(img)\n",
    "            res = client.chat.completions.create(\n",
    "                model=\"gpt-4o\",\n",
    "                messages=[{\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": [\n",
    "                        {\"type\": \"text\", \"text\": \"Extract fiscal/reporting year. Return JSON.\"},\n",
    "                        {\"type\": \"image_url\", \"image_url\": {\"url\": f\"data:image/png;base64,{b64}\"}}\n",
    "                    ]\n",
    "                }]\n",
    "            )\n",
    "            parsed = json.loads(res.choices[0].message.content)\n",
    "            if parsed.get(\"normalized_report_year\"):\n",
    "                return parsed\n",
    "    except Exception as e:\n",
    "        return {\"normalized_report_year\": None, \"original_expression\": None, \"source\": f\"Vision ERROR: {e}\"}\n",
    "    return {\"normalized_report_year\": None, \"original_expression\": None, \"source\": \"Vision NOT FOUND\"}\n",
    "\n",
    "def extract_report_year(pdf_path):\n",
    "    try:\n",
    "        text = extract_front_back_text(pdf_path)\n",
    "        prompt = build_year_prompt(text)\n",
    "        res = client.chat.completions.create(\n",
    "            model=\"gpt-4.1-mini\",\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "        )\n",
    "        parsed = json.loads(res.choices[0].message.content)\n",
    "        if parsed.get(\"normalized_report_year\"):\n",
    "            return parsed\n",
    "    except:\n",
    "        pass\n",
    "    return extract_year_from_vision(pdf_path)\n",
    "\n",
    "# ‚úÖ ‰ªªÂä°3ÔºöÂÖ¨Âè∏ÂêçÁß∞ÊèêÂèñ\n",
    "def extract_company_info(text):\n",
    "    prompt = f\"\"\"\n",
    "From the text (report front/back pages), extract:\n",
    "\n",
    "- \"company_name\": issuing company (or \"UNKNOWN\")\n",
    "- \"other_names\": abbreviations/nicknames\n",
    "- \"country\": where headquartered\n",
    "- \"reasoning\": explanation\n",
    "\n",
    "Return JSON:\n",
    "{{\n",
    "  \"company_name\": \"...\",\n",
    "  \"other_names\": [\"...\"],\n",
    "  \"country\": \"...\",\n",
    "  \"reasoning\": \"...\"\n",
    "}}\n",
    "\"\"\"\n",
    "    try:\n",
    "        res = client.chat.completions.create(\n",
    "            model=\"gpt-4.1\",\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "        )\n",
    "        result = json.loads(res.choices[0].message.content)\n",
    "    except Exception as e:\n",
    "        return {\n",
    "            \"company_name\": \"GPT_ERROR\",\n",
    "            \"other_names\": [],\n",
    "            \"country\": \"GPT_ERROR\",\n",
    "            \"reasoning\": str(e),\n",
    "            \"publisher\": None\n",
    "        }\n",
    "\n",
    "    if result.get(\"company_name\", \"\").upper() == \"UNKNOWN\":\n",
    "        try:\n",
    "            res2 = client.chat.completions.create(\n",
    "                model=\"gpt-4.1\",\n",
    "                messages=[{\"role\": \"user\", \"content\": f\"Extract publisher from text:\\n{text}\"}]\n",
    "            )\n",
    "            pub = json.loads(res2.choices[0].message.content)\n",
    "            result[\"publisher\"] = pub.get(\"publisher\", \"UNKNOWN\")\n",
    "        except:\n",
    "            result[\"publisher\"] = \"GPT_ERROR\"\n",
    "    else:\n",
    "        result[\"publisher\"] = None\n",
    "\n",
    "    return result\n",
    "\n",
    "# ‚úÖ Êï¥‰ΩìÊµÅÁ®ãÔºöÂ§ÑÁêÜÂçï‰∏™ PDF\n",
    "def process_pdf(pdf_path):\n",
    "    text = extract_front_back_text(pdf_path)\n",
    "\n",
    "    rtype = classify_report_type(text)\n",
    "    year = extract_report_year(pdf_path)\n",
    "    company = extract_company_info(text)\n",
    "\n",
    "    return {\n",
    "        \"filename\": pdf_path.name,\n",
    "        \"report_type\": rtype.get(\"report_type\"),\n",
    "        \"has_sustainability_section\": rtype.get(\"has_sustainability_section\"),\n",
    "        \"sustainability_section_name\": rtype.get(\"sustainability_section_name\"),\n",
    "        \"normalized_report_year\": year.get(\"normalized_report_year\"),\n",
    "        \"original_expression\": year.get(\"original_expression\"),\n",
    "        \"year_source\": year.get(\"source\"),\n",
    "        \"company_name\": company.get(\"company_name\"),\n",
    "        \"other_names\": \"; \".join(company.get(\"other_names\", [])),\n",
    "        \"publisher\": company.get(\"publisher\"),\n",
    "        \"country\": company.get(\"country\"),\n",
    "        \"reasoning\": company.get(\"reasoning\")\n",
    "    }\n",
    "\n",
    "# ‚úÖ ÊâπÂ§ÑÁêÜÊâßË°å\n",
    "pdf_dir = Path(\"pdf_folder\")\n",
    "output_path = Path(\"results/full_pipeline_output.csv\")\n",
    "os.makedirs(output_path.parent, exist_ok=True)\n",
    "\n",
    "pdf_files = list(pdf_dir.glob(\"*.pdf\"))\n",
    "# ‚úÖ ‰∏≤Ë°åÊâßË°åÔºåÈÅøÂÖçÂ§öËøõÁ®ãÂ∫èÂàóÂåñÈóÆÈ¢ò\n",
    "results = [process_pdf(pdf) for pdf in tqdm(pdf_files, desc=\"üîç Processing PDFs\")]\n",
    "df = pd.DataFrame(results)\n",
    "df.to_csv(output_path, index=False)\n",
    "print(f\"‚úÖ Done! Results saved to: {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "230eb0cb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "irp_pdf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
