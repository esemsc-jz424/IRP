{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "76fd0724",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import base64\n",
    "import tempfile\n",
    "from pathlib import Path\n",
    "from pdf2image import convert_from_path\n",
    "import openai\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "\n",
    "\n",
    "# Load OpenAI API key from .env file\n",
    "load_dotenv()\n",
    "client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "\n",
    "# ‚úÖ Vision Prompt\n",
    "\n",
    "\n",
    "vision_prompt = \"\"\"\n",
    "This image is from the first few pages of a corporate report.\n",
    "\n",
    "Please identify the time period that the report covers, based on any visible text, charts, or tables, body text, or headers, footer, or any other visible elements in the image\n",
    "As much as you can, you can also finf the mounth and date.\n",
    "\n",
    "\n",
    "Return examples like:\n",
    "- ‚ÄúApril 2023 ‚Äì March 2024‚Äù\n",
    "- ‚ÄúFiscal Year Ending 31 March 2023‚Äù\n",
    "- ‚Äú2022‚Äù\n",
    "- \"31 December 2022 to 30 June 2023\"\n",
    "\n",
    "If no such date range is visible, respond with ‚ÄúNOT FOUND‚Äù.\n",
    "Return only the most specific date range or fiscal year visible.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def encode_image_to_base64(image_path):\n",
    "    with open(image_path, \"rb\") as f:\n",
    "        return base64.b64encode(f.read()).decode(\"utf-8\")\n",
    "\n",
    "def call_gpt4_vision(image_path):\n",
    "    b64_image = encode_image_to_base64(image_path)\n",
    "    try:\n",
    "        response = openai.chat.completions.create(\n",
    "        model=\"gpt-4o\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "            {\"role\": \"user\", \"content\": [\n",
    "                {\"type\": \"text\", \"text\": vision_prompt},\n",
    "                {\"type\": \"image_url\", \"image_url\": {\n",
    "                    \"url\": f\"data:image/png;base64,{b64_image}\"\n",
    "                }}\n",
    "            ]}\n",
    "        ],\n",
    "        max_tokens=300\n",
    "    )\n",
    "        return response.choices[0].message.content.strip()\n",
    "    except Exception as e:\n",
    "        return f\"ERROR: {e}\"\n",
    "\n",
    "def extract_report_year_from_pdf(pdf_path, max_pages=3):\n",
    "    with tempfile.TemporaryDirectory() as tmpdir:\n",
    "        try:\n",
    "            images = convert_from_path(pdf_path, dpi=300, first_page=1, last_page=max_pages, output_folder=tmpdir)\n",
    "            for img in images:\n",
    "                img_path = Path(tmpdir) / f\"{Path(pdf_path).stem}.png\"\n",
    "                img.save(img_path)\n",
    "                result = call_gpt4_vision(img_path)\n",
    "                if \"not found\" not in result.lower():\n",
    "                    return result\n",
    "        except Exception as e:\n",
    "            return f\"ERROR: {e}\"\n",
    "    return \"NOT FOUND\"\n",
    "\n",
    "def batch_process_pdf_folder(pdf_folder, output_csv, max_pages=5):\n",
    "    results = []\n",
    "\n",
    "    for filename in tqdm(os.listdir(pdf_folder)):\n",
    "        if not filename.lower().endswith(\".pdf\"):\n",
    "            continue\n",
    "        pdf_path = os.path.join(pdf_folder, filename)\n",
    "        result = extract_report_year_from_pdf(pdf_path, max_pages)\n",
    "        results.append({\n",
    "            \"filename\": filename,\n",
    "            \"report_year_vision\": result\n",
    "        })\n",
    "\n",
    "    df = pd.DataFrame(results)\n",
    "    df.to_csv(output_csv, index=False)\n",
    "    print(f\"‚úÖ Saved results to {output_csv}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "44b0855d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|‚ñà‚ñâ        | 252/1279 [35:44<1:50:09,  6.44s/it] /opt/homebrew/Caskroom/miniconda/base/envs/irp_pdf/lib/python3.12/site-packages/PIL/Image.py:3442: DecompressionBombWarning: Image size (136875639 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
      "  warnings.warn(\n",
      " 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 855/1279 [5:05:54<41:20,  5.85s/it]      /opt/homebrew/Caskroom/miniconda/base/envs/irp_pdf/lib/python3.12/site-packages/PIL/Image.py:3442: DecompressionBombWarning: Image size (151052078 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
      "  warnings.warn(\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1279/1279 [5:47:13<00:00, 16.29s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Saved results to output/report_years_extracted_new.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    folder_path = \"pdf_folder\"  # ‚ö†Ô∏è ÊõøÊç¢Êàê‰Ω†Êú¨Âú∞PDFÊñá‰ª∂Â§πË∑ØÂæÑ\n",
    "    output_csv = \"output/report_years_extracted_new.csv\"\n",
    "    batch_process_pdf_folder(folder_path, output_csv, max_pages=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "337b2223",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "391ee270",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤‰øùÂ≠òÁÆÄÊ¥ÅÂØπÊØîÁªìÊûú‰∏∫ rfyear_comparison_results_minimal.csv\n",
      "üìä ÂåπÈÖçÊÉÖÂÜµÁªüËÆ°Ôºö\n",
      "match_result\n",
      "missing     386\n",
      "mismatch    137\n",
      "match        78\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# ËØªÂèñÊñá‰ª∂\n",
    "anno_df = pd.read_excel(\"check/rfyear_annotation.xlsx\")\n",
    "result_df = pd.read_csv(\"output/full_pipeline_results.csv\")\n",
    "\n",
    "# Ê∏ÖÊ¥óÊñá‰ª∂ÂêçÂàó\n",
    "anno_df[\"pdf_name_clean\"] = anno_df[\"pdf_name\"].str.strip().str.lower()\n",
    "result_df[\"filename_clean\"] = result_df[\"filename\"].str.strip().str.lower()\n",
    "\n",
    "# ÂêàÂπ∂‰∏§‰∏™Ë°®\n",
    "merged_df = pd.merge(\n",
    "    anno_df,\n",
    "    result_df,\n",
    "    left_on=\"pdf_name_clean\",\n",
    "    right_on=\"filename_clean\",\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "# Âπ¥‰ªΩÂØπÊØîÂáΩÊï∞\n",
    "def match_year(human, gpt):\n",
    "    if pd.isna(human) or pd.isna(gpt):\n",
    "        return \"missing\"\n",
    "    return \"match\" if str(human).strip().lower() == str(gpt).strip().lower() else \"mismatch\"\n",
    "\n",
    "# Ê∑ªÂä†ÂåπÈÖçÁªìÊûú\n",
    "merged_df[\"match_result\"] = merged_df.apply(\n",
    "    lambda row: match_year(row[\"chosen_rfyear\"], row[\"report_year_vision\"]),\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# ‰ªÖ‰øùÁïôÊúâÁî®Â≠óÊÆµ\n",
    "final_df = merged_df[[\n",
    "    \"pdf_name\", \"chosen_rfyear\", \"report_year_vision\", \"match_result\"\n",
    "]]\n",
    "\n",
    "# ‰øùÂ≠òÁªìÊûú\n",
    "final_df.to_csv(\"rfyear_comparison_results_minimal.csv\", index=False)\n",
    "\n",
    "# ËæìÂá∫ÁªüËÆ°\n",
    "print(\"‚úÖ Â∑≤‰øùÂ≠òÁÆÄÊ¥ÅÂØπÊØîÁªìÊûú‰∏∫ rfyear_comparison_results_minimal.csv\")\n",
    "print(\"üìä ÂåπÈÖçÊÉÖÂÜµÁªüËÆ°Ôºö\")\n",
    "print(final_df[\"match_result\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "15d0c044",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤‰øùÂ≠òÁÆÄÊ¥ÅÂØπÊØîÁªìÊûú‰∏∫ rfyear_comparison_results_minimal.csv\n",
      "üìä ÂåπÈÖçÊÉÖÂÜµÁªüËÆ°Ôºö\n",
      "match_result\n",
      "missing     386\n",
      "mismatch    215\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# ËØªÂèñÊñá‰ª∂\n",
    "anno_df = pd.read_excel(\"check/rfyear_annotation.xlsx\")\n",
    "result_df = pd.read_csv(\"output/report_years_extracted_new.csv\")\n",
    "\n",
    "# Ê∏ÖÊ¥óÊñá‰ª∂ÂêçÂàó\n",
    "anno_df[\"pdf_name_clean\"] = anno_df[\"pdf_name\"].str.strip().str.lower()\n",
    "result_df[\"filename_clean\"] = result_df[\"filename\"].str.strip().str.lower()\n",
    "\n",
    "# ÂêàÂπ∂‰∏§‰∏™Ë°®\n",
    "merged_df = pd.merge(\n",
    "    anno_df,\n",
    "    result_df,\n",
    "    left_on=\"pdf_name_clean\",\n",
    "    right_on=\"filename_clean\",\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "# Âπ¥‰ªΩÂØπÊØîÂáΩÊï∞\n",
    "def match_year(human, gpt):\n",
    "    if pd.isna(human) or pd.isna(gpt):\n",
    "        return \"missing\"\n",
    "    return \"match\" if str(human).strip().lower() == str(gpt).strip().lower() else \"mismatch\"\n",
    "\n",
    "# Ê∑ªÂä†ÂåπÈÖçÁªìÊûú\n",
    "merged_df[\"match_result\"] = merged_df.apply(\n",
    "    lambda row: match_year(row[\"chosen_rfyear\"], row[\"report_year_vision\"]),\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# ‰ªÖ‰øùÁïôÊúâÁî®Â≠óÊÆµ\n",
    "final_df = merged_df[[\n",
    "    \"pdf_name\", \"chosen_rfyear\", \"report_year_vision\", \"match_result\"\n",
    "]]\n",
    "\n",
    "# ‰øùÂ≠òÁªìÊûú\n",
    "final_df.to_csv(\"rfyear_comparison_results_minimal.csv\", index=False)\n",
    "\n",
    "# ËæìÂá∫ÁªüËÆ°\n",
    "print(\"‚úÖ Â∑≤‰øùÂ≠òÁÆÄÊ¥ÅÂØπÊØîÁªìÊûú‰∏∫ rfyear_comparison_results_minimal.csv\")\n",
    "print(\"üìä ÂåπÈÖçÊÉÖÂÜµÁªüËÆ°Ôºö\")\n",
    "print(final_df[\"match_result\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ec466a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea611aaa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99079149",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a07953a4",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "93ac0059",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import fitz  # PyMuPDF\n",
    "import openai\n",
    "import pytesseract\n",
    "import tempfile\n",
    "import base64\n",
    "import json\n",
    "from pdf2image import convert_from_path\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "\n",
    "\n",
    "# Load OpenAI API key from .env file\n",
    "load_dotenv()\n",
    "client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "\n",
    "# ‚úÖ Vision Prompt\n",
    "openai.api_key = \"sk-...\"  # ‚Üê ËØ∑ÊõøÊç¢‰∏∫‰Ω†ÁöÑ API key\n",
    "\n",
    "def extract_front_back_text(pdf_path, front_n=20, back_n=20):\n",
    "    try:\n",
    "        doc = fitz.open(pdf_path)\n",
    "        texts = [doc[i].get_text() for i in range(min(front_n, len(doc)))]\n",
    "        texts += [doc[i].get_text() for i in range(max(0, len(doc) - back_n), len(doc))]\n",
    "        doc.close()\n",
    "        full_text = \"\\n\".join(texts)\n",
    "        if len(full_text.strip()) < 50:\n",
    "            raise ValueError(\"Too little text, fallback to OCR.\")\n",
    "        return full_text\n",
    "    except:\n",
    "        return extract_text_with_ocr(pdf_path)\n",
    "    \n",
    "\n",
    "def extract_text_with_ocr(pdf_path, dpi=300):\n",
    "    with tempfile.TemporaryDirectory() as path:\n",
    "        images = convert_from_path(pdf_path, dpi=dpi, output_folder=path)\n",
    "        text_parts = [pytesseract.image_to_string(img) for img in images[:3] + images[-3:]]\n",
    "        return \"\\n\".join(text_parts)\n",
    "    \n",
    "def build_report_year_prompt(text):\n",
    "    return f\"\"\"\n",
    "You are an assistant helping extract the reporting year or fiscal year from the following corporate report excerpt.\n",
    "\n",
    "1. Look for expressions such as:\n",
    "   - \"For the year ended 31 March 2022\"\n",
    "   - \"Reporting period: April 2021 ‚Äì March 2022\"\n",
    "   - \"FY2020\", etc.\n",
    "2. If found, return this JSON:\n",
    "{{\n",
    "  \"report_year\": \"April 2021 ‚Äì March 2022\",\n",
    "  \"source\": \"Page 2, main text\"\n",
    "}}\n",
    "\n",
    "If not found:\n",
    "{{\n",
    "  \"report_year\": null,\n",
    "  \"source\": \"NOT FOUND\"\n",
    "}}\n",
    "\n",
    "Report text:\n",
    "{text}\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def encode_image_to_base64(pil_image):\n",
    "    with tempfile.NamedTemporaryFile(suffix=\".png\") as f:\n",
    "        pil_image.save(f.name, format=\"PNG\")\n",
    "        with open(f.name, \"rb\") as image_file:\n",
    "            return base64.b64encode(image_file.read()).decode(\"utf-8\")\n",
    "        \n",
    "def extract_year_from_vision(pdf_path, client, page_limit=3):\n",
    "    images = convert_from_path(pdf_path, dpi=300)\n",
    "    for i, img in enumerate(images[:page_limit]):\n",
    "        b64 = encode_image_to_base64(img)\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-4o\",\n",
    "            messages=[\n",
    "                {\"role\": \"user\", \"content\": [\n",
    "                    {\"type\": \"text\", \"text\": f\"Please extract the fiscal year or reporting period from page {i+1}.\"},\n",
    "                    {\"type\": \"image_url\", \"image_url\": {\"url\": f\"data:image/png;base64,{b64}\"}}\n",
    "                ]}\n",
    "            ],\n",
    "            max_tokens=300\n",
    "        )\n",
    "        result = response.choices[0].message.content\n",
    "        if \"not found\" not in result.lower():\n",
    "            return {\"report_year\": result.strip(), \"source\": f\"Vision page {i+1}\"}\n",
    "    return {\"report_year\": None, \"source\": \"Vision NOT FOUND\"}\n",
    "\n",
    "def extract_report_year(pdf_path, client):\n",
    "    text = extract_front_back_text(pdf_path)\n",
    "    prompt = build_report_year_prompt(text)\n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-4.1-mini\",\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "            temperature=0,\n",
    "            max_tokens=300\n",
    "        )\n",
    "        content = response.choices[0].message.content\n",
    "        parsed = json.loads(content) if content.startswith(\"{\") else eval(content)\n",
    "        if parsed[\"report_year\"]:\n",
    "            return parsed\n",
    "    except:\n",
    "        pass\n",
    "    return extract_year_from_vision(pdf_path, client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2cb7edf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "256it [11:29,  1.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MuPDF error: format error: cmsOpenProfileFromMem failed\n",
      "\n",
      "MuPDF error: format error: cmsOpenProfileFromMem failed\n",
      "\n",
      "MuPDF error: format error: cmsOpenProfileFromMem failed\n",
      "\n",
      "MuPDF error: format error: cmsOpenProfileFromMem failed\n",
      "\n",
      "MuPDF error: format error: cmsOpenProfileFromMem failed\n",
      "\n",
      "MuPDF error: format error: cmsOpenProfileFromMem failed\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "724it [36:16,  2.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MuPDF error: format error: object is not a stream\n",
      "\n",
      "MuPDF error: format error: object is not a stream\n",
      "\n",
      "MuPDF error: format error: object is not a stream\n",
      "\n",
      "MuPDF error: format error: object is not a stream\n",
      "\n",
      "MuPDF error: format error: object is not a stream\n",
      "\n",
      "MuPDF error: format error: object is not a stream\n",
      "\n",
      "MuPDF error: format error: object is not a stream\n",
      "\n",
      "MuPDF error: format error: object is not a stream\n",
      "\n",
      "MuPDF error: format error: object is not a stream\n",
      "\n",
      "MuPDF error: format error: object is not a stream\n",
      "\n",
      "MuPDF error: format error: object is not a stream\n",
      "\n",
      "MuPDF error: format error: object is not a stream\n",
      "\n",
      "MuPDF error: format error: object is not a stream\n",
      "\n",
      "MuPDF error: format error: object is not a stream\n",
      "\n",
      "MuPDF error: format error: object is not a stream\n",
      "\n",
      "MuPDF error: format error: object is not a stream\n",
      "\n",
      "MuPDF error: format error: object is not a stream\n",
      "\n",
      "MuPDF error: format error: object is not a stream\n",
      "\n",
      "MuPDF error: format error: object is not a stream\n",
      "\n",
      "MuPDF error: format error: object is not a stream\n",
      "\n",
      "MuPDF error: format error: object is not a stream\n",
      "\n",
      "MuPDF error: format error: object is not a stream\n",
      "\n",
      "MuPDF error: format error: object is not a stream\n",
      "\n",
      "MuPDF error: format error: object is not a stream\n",
      "\n",
      "MuPDF error: format error: object is not a stream\n",
      "\n",
      "MuPDF error: format error: object is not a stream\n",
      "\n",
      "MuPDF error: format error: object is not a stream\n",
      "\n",
      "MuPDF error: format error: object is not a stream\n",
      "\n",
      "MuPDF error: format error: object is not a stream\n",
      "\n",
      "MuPDF error: format error: object is not a stream\n",
      "\n",
      "MuPDF error: format error: object is not a stream\n",
      "\n",
      "MuPDF error: format error: object is not a stream\n",
      "\n",
      "MuPDF error: format error: object is not a stream\n",
      "\n",
      "MuPDF error: format error: object is not a stream\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "835it [40:33,  2.04s/it]"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "pdf_dir = \"pdf_folder\"  # ÊõøÊç¢‰∏∫‰Ω†ÁöÑÊñá‰ª∂Â§πË∑ØÂæÑ\n",
    "load_dotenv()\n",
    "client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "\n",
    "\n",
    "results = []\n",
    "for pdf in tqdm(Path(pdf_dir).glob(\"*.pdf\")):\n",
    "    try:\n",
    "        out = extract_report_year(str(pdf), client)\n",
    "        out[\"filename\"] = pdf.name\n",
    "        results.append(out)\n",
    "    except Exception as e:\n",
    "        results.append({\"filename\": pdf.name, \"report_year\": None, \"source\": f\"ERROR: {e}\"})\n",
    "\n",
    "df = pd.DataFrame(results)\n",
    "df.to_csv(\"results/extracted_report_years_mini.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc04b2f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69022207",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b75695f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b3280ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ö†Ô∏è GPT-4.1-mini failed on AAK_AB_aak-sustainability-report-2012-2013_8y6o3xp0.pdf, fallback to Vision...\n",
      "‚ö†Ô∏è GPT-4.1-mini failed on 888_Holdings_888_Holdings_PLC_Annual_Report__Accounts_2022_4ya4gkz2.pdf, fallback to Vision...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ö†Ô∏è GPT-4.1-mini failed on ABC_Holdings_Limited_P020160316609968328069_w68f32zb.pdf, fallback to Vision...\n",
      "‚ö†Ô∏è GPT-4.1-mini failed on AFLAC_Inc_2013-csr-report-final_oxgizar1.pdf, fallback to Vision...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ö†Ô∏è GPT-4.1-mini failed on AIA_Engineering_Ltd_ANNUALREPORT19_20_7ta9u15v.pdf, fallback to Vision...\n",
      "‚ö†Ô∏è GPT-4.1-mini failed on AIA_Group_Ltd_aia-annual-report-2015-eng_6dpw11ja.pdf, fallback to Vision...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ö†Ô∏è GPT-4.1-mini failed on AIB_Group_PLC_annual-financial-report-2010_nzf6dpw1.pdf, fallback to Vision...\n",
      "‚ö†Ô∏è GPT-4.1-mini failed on AIB_Group_PLC_annual-report-2013_w2uuexld.pdf, fallback to Vision...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ö†Ô∏è GPT-4.1-mini failed on AKSA_A40C80A20FF2492CAC2C9CD3A2967D88_u2o5uhav.pdf, fallback to Vision...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ö†Ô∏è GPT-4.1-mini failed on AKSA_Aksa-Dogalgaz-Annual-Report-2019_w9j206fd.pdf, fallback to Vision...\n",
      "‚ö†Ô∏è GPT-4.1-mini failed on AMETEK_Inc_86f51b22-fde1-4f26-afc9-5a60c2a24431_fd0pue9s.pdf, fallback to Vision...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ö†Ô∏è GPT-4.1-mini failed on Acast_AB_acast-annual-report-2021_5hv0716n.pdf, fallback to Vision...\n",
      "‚ö†Ô∏è GPT-4.1-mini failed on Accell_Group_NV_Heerenveen_AnualReport2014_dfllq4qw.pdf, fallback to Vision...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ö†Ô∏è GPT-4.1-mini failed on Access_Co_Ltd_Sustainability_Report_2022_4phm0wik.pdf, fallback to Vision...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ö†Ô∏è GPT-4.1-mini failed on Armstrong_Flooring_Inc_SustainabilityReport-2020_kot54emv.pdf, fallback to Vision...\n",
      "‚ö†Ô∏è GPT-4.1-mini failed on Arvind_Ltd_Arvind_AR_2022-23_0_iwp4673c.pdf, fallback to Vision...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "üìÑ Processing PDFs:   9%|‚ñâ         | 114/1277 [05:14<13:53,  1.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ö†Ô∏è GPT-4.1-mini failed on BASF_SE_2012_BASF_Report_lmq79gwn.pdf, fallback to Vision...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ö†Ô∏è GPT-4.1-mini failed on Boryung_Corporation_EBB3B4EBA0B920ECA780EC868DEAB080EB8AA5EAB2BDEC9881EBB3B4EAB3A0EC849CEC9881EBACB8_ebpit5lz.pdf, fallback to Vision...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ö†Ô∏è GPT-4.1-mini failed on EKI_Energy_Services_Limited_69298543284_zj7y1tjh.pdf, fallback to Vision...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ö†Ô∏è GPT-4.1-mini failed on Hansae_Yes24_Holdings_Co_Ltd_HANSAE20YES2420HOLDINGS20ESG20REPORT202022_th5kzsfk.pdf, fallback to Vision...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ö†Ô∏è GPT-4.1-mini failed on Home_Inns__Hotels_Management_Inc_Barclays_Bank_PLC_Annual_Report_202014_5lj1epic.pdf, fallback to Vision...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ö†Ô∏è GPT-4.1-mini failed on Hyosung_Corp_SR_2020_en_8g98j6gk.pdf, fallback to Vision...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "üìÑ Processing PDFs:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 920/1277 [28:21<08:11,  1.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ö†Ô∏è GPT-4.1-mini failed on Tam_Jai_International_Co_Ltd_2022083101184_go5rbp4a.pdf, fallback to Vision...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ö†Ô∏è GPT-4.1-mini failed on Unknown_2014SustainRpt_FNL_lr_7mrwsfm7.pdf, fallback to Vision...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ö†Ô∏è GPT-4.1-mini failed on Unknown_2023042101335_kyzhtmjn.pdf, fallback to Vision...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "üìÑ Processing PDFs:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 1174/1277 [34:38<04:43,  2.75s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ö†Ô∏è GPT-4.1-mini failed on Unknown_23076_Whitbread_AR2020_web_0v2mxh4f.pdf, fallback to Vision...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ö†Ô∏è GPT-4.1-mini failed on Unknown_adbi-managing-transition-low-carbon-economy_087is5zy.pdf, fallback to Vision...\n",
      "‚ö†Ô∏è GPT-4.1-mini failed on Unknown_adp07-sus-fr_95qx6prh.pdf, fallback to Vision...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "üìÑ Processing PDFs: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1277/1277 [38:47<00:00,  1.82s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ Extraction complete! Results saved to: results/extracted_report_years_mini.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import fitz  # PyMuPDF\n",
    "import openai\n",
    "import pytesseract\n",
    "import tempfile\n",
    "import base64\n",
    "import json\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from dotenv import load_dotenv\n",
    "from tqdm import tqdm\n",
    "from pdf2image import convert_from_path\n",
    "from PIL import Image\n",
    "from openai import OpenAI\n",
    "\n",
    "# ========== 1. ÂàùÂßãÂåñ OpenAI ==========\n",
    "load_dotenv()\n",
    "client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "\n",
    "# ========== 2. ÊèêÂèñÊñáÊú¨ÔºöÂâçÂêé20È°µ ==========\n",
    "def extract_front_back_text(pdf_path, front_n=10, back_n=10):\n",
    "    try:\n",
    "        doc = fitz.open(pdf_path)\n",
    "        texts = [doc[i].get_text() for i in range(min(front_n, len(doc)))]\n",
    "        texts += [doc[i].get_text() for i in range(max(0, len(doc) - back_n), len(doc))]\n",
    "        doc.close()\n",
    "        full_text = \"\\n\".join(texts)\n",
    "        if len(full_text.strip()) < 50:\n",
    "            raise ValueError(\"Too little text\")\n",
    "        return full_text\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è PyMuPDF failed on {pdf_path.name}, switching to OCR...\")\n",
    "        return extract_text_with_ocr(pdf_path)\n",
    "\n",
    "# ========== 3. OCR Ë°•Êïë ==========\n",
    "def extract_text_with_ocr(pdf_path, dpi=300):\n",
    "    with tempfile.TemporaryDirectory() as path:\n",
    "        images = convert_from_path(pdf_path, dpi=dpi, output_folder=path)\n",
    "        text_parts = [pytesseract.image_to_string(img) for img in images[:3] + images[-3:]]\n",
    "        return \"\\n\".join(text_parts)\n",
    "\n",
    "# ========== 4. ÊûÑÈÄ† Prompt ==========\n",
    "def build_report_year_prompt(text):\n",
    "    return f\"\"\"\n",
    "You are an assistant helping extract the reporting year or fiscal year from the following corporate report excerpt.\n",
    "\n",
    "1. Look for expressions such as:\n",
    "   - \"For the year ended 31 March 2022\"\n",
    "   - \"Reporting period: April 2021 ‚Äì March 2022\"\n",
    "   - \"FY2020\", etc.\n",
    "2. If found, return this JSON:\n",
    "{{\n",
    "  \"report_year\": \"April 2021 ‚Äì March 2022\",\n",
    "  \"source\": \"Page 2, main text\"\n",
    "}}\n",
    "\n",
    "If not found:\n",
    "{{\n",
    "  \"report_year\": null,\n",
    "  \"source\": \"NOT FOUND\"\n",
    "}}\n",
    "\n",
    "Report text:\n",
    "{text}\n",
    "\"\"\"\n",
    "\n",
    "# ========== 5. Vision Ê®°ÂûãËæÖÂä© ==========\n",
    "def encode_image_to_base64(pil_image):\n",
    "    with tempfile.NamedTemporaryFile(suffix=\".png\") as f:\n",
    "        pil_image.save(f.name, format=\"PNG\")\n",
    "        with open(f.name, \"rb\") as image_file:\n",
    "            return base64.b64encode(image_file.read()).decode(\"utf-8\")\n",
    "\n",
    "def extract_year_from_vision(pdf_path, client, page_limit=3):\n",
    "    try:\n",
    "        images = convert_from_path(pdf_path, dpi=200)\n",
    "        for i, img in enumerate(images[:page_limit]):\n",
    "            b64 = encode_image_to_base64(img)\n",
    "            response = client.chat.completions.create(\n",
    "                model=\"gpt-4o\",\n",
    "                messages=[\n",
    "                    {\"role\": \"user\", \"content\": [\n",
    "                        {\"type\": \"text\", \"text\": f\"Please extract the fiscal year or reporting period from page {i+1}.\"},\n",
    "                        {\"type\": \"image_url\", \"image_url\": {\"url\": f\"data:image/png;base64,{b64}\"}}\n",
    "                    ]}\n",
    "                ],\n",
    "                max_tokens=300\n",
    "            )\n",
    "            result = response.choices[0].message.content\n",
    "            if \"not found\" not in result.lower():\n",
    "                return {\"report_year\": result.strip(), \"source\": f\"Vision page {i+1}\"}\n",
    "    except Exception as e:\n",
    "        return {\"report_year\": None, \"source\": f\"Vision ERROR: {e}\"}\n",
    "    return {\"report_year\": None, \"source\": \"Vision NOT FOUND\"}\n",
    "\n",
    "# ========== 6. ‰∏ªÂáΩÊï∞ÔºöÂÖàÊñáÊú¨ÔºåÂÜç Vision ==========\n",
    "def extract_report_year(pdf_path, client):\n",
    "    try:\n",
    "        text = extract_front_back_text(pdf_path)\n",
    "        prompt = build_report_year_prompt(text)\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-4.1-mini\",\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "            temperature=0,\n",
    "            max_tokens=300\n",
    "        )\n",
    "        content = response.choices[0].message.content\n",
    "        parsed = json.loads(content) if content.startswith(\"{\") else eval(content)\n",
    "        if parsed.get(\"report_year\"):\n",
    "            return parsed\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è GPT-4.1-mini failed on {Path(pdf_path).name}, fallback to Vision...\")\n",
    "    return extract_year_from_vision(pdf_path, client)\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "# Â§öÁ∫øÁ®ãÂ§ÑÁêÜÂáΩÊï∞\n",
    "def process_pdf(pdf_path):\n",
    "    try:\n",
    "        out = extract_report_year(str(pdf_path), client)\n",
    "        out[\"filename\"] = pdf_path.name\n",
    "    except Exception as e:\n",
    "        out = {\"filename\": pdf_path.name, \"report_year\": None, \"source\": f\"ERROR: {e}\"}\n",
    "    return out\n",
    "\n",
    "def batch_extract_years_multithread(pdf_dir, output_csv=\"results/extracted_report_years_mini.csv\", n_jobs=2):\n",
    "    pdf_dir = Path(pdf_dir)\n",
    "    pdf_files = sorted(pdf_dir.glob(\"*.pdf\"))\n",
    "    os.makedirs(Path(output_csv).parent, exist_ok=True)\n",
    "\n",
    "    # ‚úÖ Âπ∂Ë°åÂ§ÑÁêÜ\n",
    "    results = Parallel(n_jobs=n_jobs, prefer=\"threads\")(\n",
    "        delayed(process_pdf)(pdf) for pdf in tqdm(pdf_files, desc=\"üìÑ Processing PDFs\")\n",
    "    )\n",
    "\n",
    "    df = pd.DataFrame(results)\n",
    "    df.to_csv(output_csv, index=False)\n",
    "    print(f\"\\n‚úÖ Extraction complete! Results saved to: {output_csv}\")\n",
    "\n",
    "# ========== 8. ËøêË°å ==========\n",
    "if __name__ == \"__main__\":\n",
    "    batch_extract_years_multithread(\"pdf_folder\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "986b71c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤‰øùÂ≠òÁÆÄÊ¥ÅÂØπÊØîÁªìÊûú‰∏∫ rfyear_comparison_results_minimal.csv\n",
      "üìä ÂåπÈÖçÊÉÖÂÜµÁªüËÆ°Ôºö\n",
      "match_result\n",
      "missing     386\n",
      "mismatch    215\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# ËØªÂèñÊñá‰ª∂\n",
    "anno_df = pd.read_excel(\"check/rfyear_annotation.xlsx\")\n",
    "result_df = pd.read_csv(\"output/report_years_extracted_new.csv\")\n",
    "\n",
    "# Ê∏ÖÊ¥óÊñá‰ª∂ÂêçÂàó\n",
    "anno_df[\"pdf_name_clean\"] = anno_df[\"pdf_name\"].str.strip().str.lower()\n",
    "result_df[\"filename_clean\"] = result_df[\"filename\"].str.strip().str.lower()\n",
    "\n",
    "# ÂêàÂπ∂‰∏§‰∏™Ë°®\n",
    "merged_df = pd.merge(\n",
    "    anno_df,\n",
    "    result_df,\n",
    "    left_on=\"pdf_name_clean\",\n",
    "    right_on=\"filename_clean\",\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "# Âπ¥‰ªΩÂØπÊØîÂáΩÊï∞\n",
    "def match_year(human, gpt):\n",
    "    if pd.isna(human) or pd.isna(gpt):\n",
    "        return \"missing\"\n",
    "    return \"match\" if str(human).strip().lower() == str(gpt).strip().lower() else \"mismatch\"\n",
    "\n",
    "# Ê∑ªÂä†ÂåπÈÖçÁªìÊûú\n",
    "merged_df[\"match_result\"] = merged_df.apply(\n",
    "    lambda row: match_year(row[\"chosen_rfyear\"], row[\"report_year_vision\"]),\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# ‰ªÖ‰øùÁïôÊúâÁî®Â≠óÊÆµ\n",
    "final_df = merged_df[[\n",
    "    \"pdf_name\", \"chosen_rfyear\", \"report_year_vision\", \"match_result\"\n",
    "]]\n",
    "\n",
    "# ‰øùÂ≠òÁªìÊûú\n",
    "final_df.to_csv(\"rfyear_comparison_results_minimal.csv\", index=False)\n",
    "\n",
    "# ËæìÂá∫ÁªüËÆ°\n",
    "print(\"‚úÖ Â∑≤‰øùÂ≠òÁÆÄÊ¥ÅÂØπÊØîÁªìÊûú‰∏∫ rfyear_comparison_results_minimal.csv\")\n",
    "print(\"üìä ÂåπÈÖçÊÉÖÂÜµÁªüËÆ°Ôºö\")\n",
    "print(final_df[\"match_result\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa2420e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ ÂêàÂπ∂Ê†∑Êú¨Êï∞Ôºö224\n",
      "‚úÖ ÂåπÈÖçÊ≠£Á°ÆÊï∞Ôºö78\n",
      "‚úÖ ÂáÜÁ°ÆÁéáÔºàaccuracyÔºâÔºö34.82%\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "# 1. ËØªÂèñ‰∏§‰∏™Êñá‰ª∂\n",
    "gpt_df = pd.read_csv(\"results/extracted_report_years_mini.csv\")  # ÊèêÂèñÁªìÊûú\n",
    "label_df = pd.read_excel(\"check/rfyear_annotation.xlsx\")         # ‰∫∫Â∑•Ê†áÊ≥®Êñá‰ª∂\n",
    "\n",
    "# 2. ÈáçÂëΩÂêçÂàó‰ª•‰æøÂØπÈΩêÂêàÂπ∂\n",
    "gpt_df.rename(columns={\"filename\": \"pdf_name\", \"report_year\": \"report_year_pred\"}, inplace=True)\n",
    "\n",
    "# 3. ÂêàÂπ∂‰∏§‰∏™Ë°®Ôºàinner joinÔºåÂè™‰øùÁïô‰∏§‰∏™ÈÉΩÊúâÁöÑ pdfÔºâ\n",
    "merged = pd.merge(label_df, gpt_df, on=\"pdf_name\", how=\"inner\")\n",
    "\n",
    "# 4. Ê†áÂáÜÂåñÂ≠óÁ¨¶‰∏≤Ê†ºÂºèÔºàÂéªÈô§Á©∫Ê†ºÂ§ßÂ∞èÂÜôÁ≠âÔºâ\n",
    "merged[\"report_year_pred\"] = merged[\"report_year_pred\"].astype(str).str.strip().str.lower()\n",
    "merged[\"chosen_rfyear\"] = merged[\"chosen_rfyear\"].astype(str).str.strip().str.lower()\n",
    "\n",
    "# 5. ÂÆö‰πâÂåπÈÖçÈÄªËæëÔºàÂÆåÂÖ®ÂåπÈÖçÂç≥ÂèØÔºâ\n",
    "merged[\"match\"] = merged[\"report_year_pred\"] == merged[\"chosen_rfyear\"]\n",
    "\n",
    "# 6. ÁªüËÆ°ÊåáÊ†á\n",
    "total = len(merged)\n",
    "correct = merged[\"match\"].sum()\n",
    "accuracy = correct / total\n",
    "\n",
    "print(f\"‚úÖ ÂêàÂπ∂Ê†∑Êú¨Êï∞Ôºö{total}\")\n",
    "print(f\"‚úÖ ÂåπÈÖçÊ≠£Á°ÆÊï∞Ôºö{correct}\")\n",
    "print(f\"‚úÖ ÂáÜÁ°ÆÁéáÔºàaccuracyÔºâÔºö{accuracy:.2%}\")\n",
    "\n",
    "# 7. ÂèØÈÄâÔºö‰øùÂ≠òÂØπÊØîÁªìÊûú\n",
    "merged[[\"pdf_name\", \"chosen_rfyear\", \"report_year_pred\", \"match\"]].to_csv(\"eval/year_comparison.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ab1cdeb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "irp_pdf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
