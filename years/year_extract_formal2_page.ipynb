{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1b3280ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ğŸ“„ Processing PDFs:   2%|â–         | 22/1277 [00:29<28:44,  1.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ GPT-4.1-mini failed on Absolute_Software_Corp_abt-csr-report_chc5albm.pdf, fallback to Vision...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ğŸ“„ Processing PDFs:   6%|â–‹         | 82/1277 [01:45<21:59,  1.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ GPT-4.1-mini failed on Armstrong_Flooring_Inc_SustainabilityReport-2020_kot54emv.pdf, fallback to Vision...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ğŸ“„ Processing PDFs:   7%|â–‹         | 84/1277 [01:46<13:31,  1.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ GPT-4.1-mini failed on Arvind_Ltd_Arvind_AR_2022-23_0_iwp4673c.pdf, fallback to Vision...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ğŸ“„ Processing PDFs:   9%|â–‰         | 114/1277 [02:21<18:32,  1.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ GPT-4.1-mini failed on BASF_SE_2012_BASF_Report_lmq79gwn.pdf, fallback to Vision...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ğŸ“„ Processing PDFs:  12%|â–ˆâ–        | 158/1277 [03:35<32:38,  1.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ GPT-4.1-mini failed on Boryung_Corporation_EBB3B4EBA0B920ECA780EC868DEAB080EB8AA5EAB2BDEC9881EBB3B4EAB3A0EC849CEC9881EBACB8_ebpit5lz.pdf, fallback to Vision...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ğŸ“„ Processing PDFs:  14%|â–ˆâ–        | 183/1277 [04:15<29:20,  1.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ GPT-4.1-mini failed on CF_Industries_Holdings_Inc_ar2011_4ocuzeva.pdf, fallback to Vision...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ğŸ“„ Processing PDFs:  19%|â–ˆâ–‰        | 240/1277 [05:45<17:38,  1.02s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ GPT-4.1-mini failed on Columbia_Banking_System_Inc__-Old_Annual20Progress20Report202022-23_huqi1n89.pdf, fallback to Vision...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ğŸ“„ Processing PDFs:  23%|â–ˆâ–ˆâ–       | 290/1277 [07:31<22:44,  1.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ GPT-4.1-mini failed on EKI_Energy_Services_Limited_69298543284_zj7y1tjh.pdf, fallback to Vision...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ğŸ“„ Processing PDFs:  23%|â–ˆâ–ˆâ–       | 296/1277 [07:39<22:13,  1.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ GPT-4.1-mini failed on Edison_Mission_Energy_2014-sce-corporate-responsibility-report_j27jgmh6.pdf, fallback to Vision...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ğŸ“„ Processing PDFs:  32%|â–ˆâ–ˆâ–ˆâ–      | 406/1277 [10:11<18:50,  1.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ GPT-4.1-mini failed on Hansae_Yes24_Holdings_Co_Ltd_HANSAE20YES2420HOLDINGS20ESG20REPORT202022_th5kzsfk.pdf, fallback to Vision...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ğŸ“„ Processing PDFs:  34%|â–ˆâ–ˆâ–ˆâ–      | 434/1277 [10:40<11:43,  1.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ GPT-4.1-mini failed on Home_Inns__Hotels_Management_Inc_Barclays_Bank_PLC_Annual_Report_202014_5lj1epic.pdf, fallback to Vision...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ğŸ“„ Processing PDFs:  34%|â–ˆâ–ˆâ–ˆâ–      | 440/1277 [10:47<16:07,  1.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ GPT-4.1-mini failed on Hyosung_Corp_SR_2020_en_8g98j6gk.pdf, fallback to Vision...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ğŸ“„ Processing PDFs:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 920/1277 [21:34<08:18,  1.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ GPT-4.1-mini failed on Tam_Jai_International_Co_Ltd_2022083101184_go5rbp4a.pdf, fallback to Vision...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ğŸ“„ Processing PDFs:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 1040/1277 [23:50<03:59,  1.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ GPT-4.1-mini failed on Unknown_2014SustainRpt_FNL_lr_7mrwsfm7.pdf, fallback to Vision...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ğŸ“„ Processing PDFs:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 1174/1277 [26:35<01:55,  1.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ GPT-4.1-mini failed on Unknown_2023042101335_kyzhtmjn.pdf, fallback to Vision...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ğŸ“„ Processing PDFs:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 1192/1277 [26:58<01:42,  1.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ GPT-4.1-mini failed on Unknown_23076_Whitbread_AR2020_web_0v2mxh4f.pdf, fallback to Vision...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ğŸ“„ Processing PDFs: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 1274/1277 [29:03<00:04,  1.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ GPT-4.1-mini failed on Unknown_adbi-managing-transition-low-carbon-economy_087is5zy.pdf, fallback to Vision...\n",
      "âš ï¸ GPT-4.1-mini failed on Unknown_adp07-sus-fr_95qx6prh.pdf, fallback to Vision...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ğŸ“„ Processing PDFs: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1277/1277 [29:04<00:00,  1.37s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âœ… Extraction complete! Results saved to: results/extracted_report_years_formal1.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import fitz  # PyMuPDF\n",
    "import openai\n",
    "import pytesseract\n",
    "import tempfile\n",
    "import base64\n",
    "import json\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from dotenv import load_dotenv\n",
    "from tqdm import tqdm\n",
    "from pdf2image import convert_from_path\n",
    "from PIL import Image\n",
    "from openai import OpenAI\n",
    "\n",
    "# ========== 1. åˆå§‹åŒ– OpenAI ==========\n",
    "load_dotenv()\n",
    "client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "\n",
    "# ========== 2. æå–æ–‡æœ¬ï¼šå‰å20é¡µ ==========\n",
    "def extract_front_back_text(pdf_path, front_n=10, back_n=10):\n",
    "    try:\n",
    "        doc = fitz.open(pdf_path)\n",
    "        texts = [doc[i].get_text() for i in range(min(front_n, len(doc)))]\n",
    "        texts += [doc[i].get_text() for i in range(max(0, len(doc) - back_n), len(doc))]\n",
    "        doc.close()\n",
    "        full_text = \"\\n\".join(texts)\n",
    "        if len(full_text.strip()) < 50:\n",
    "            raise ValueError(\"Too little text\")\n",
    "        return full_text\n",
    "    except Exception as e:\n",
    "        print(f\"âš ï¸ PyMuPDF failed on {pdf_path.name}, switching to OCR...\")\n",
    "        return extract_text_with_ocr(pdf_path)\n",
    "\n",
    "# ========== 3. OCR è¡¥æ•‘ ==========\n",
    "def extract_text_with_ocr(pdf_path, dpi=300):\n",
    "    with tempfile.TemporaryDirectory() as path:\n",
    "        images = convert_from_path(pdf_path, dpi=dpi, output_folder=path)\n",
    "        text_parts = [pytesseract.image_to_string(img) for img in images[:3] + images[-3:]]\n",
    "        return \"\\n\".join(text_parts)\n",
    "\n",
    "# ========== 4. æ„é€  Prompt ==========\n",
    "def build_report_year_prompt(text):\n",
    "    return f\"\"\"\n",
    "You are an expert assistant helping to extract reporting years from corporate reports.\n",
    "\n",
    "Please complete the following tasks after carefully reading the text below:\n",
    "\n",
    "---\n",
    "\n",
    "### Task 1: Identify any **fiscal year**, **reporting period**, or **financial year** expressions.\n",
    "\n",
    "Common examples include:\n",
    "- \"for the year ended 31 December 2021\"\n",
    "- \"reporting period: April 2021 â€“ March 2022\"\n",
    "- \"2011â€“14\" or \"FY2017\"\n",
    "- \"2020 ESG highlights\"\n",
    "- \"2013 Corporate Report\"\n",
    "\n",
    "---\n",
    "\n",
    "### Task 2: Normalize each valid expression into a standardized format:\n",
    "\n",
    "1. If the expression is a **single year**, like `\"2013\"` or `\"FY2020\"`, output `\"2013\"` or `\"2020\"` as-is.\n",
    "2. If it is a **range of years only**, like `\"2014â€“15\"`, output `\"2014 to 2015\"`. Do **not** add months or days.\n",
    "3. If full dates are mentioned (e.g., `\"1st April 2020 â€“ 31st March 2021\"`), remove ordinal suffixes (`1st`, `2nd`, etc.) and format as:\n",
    "   `\"1 April 2020 to 31 March 2021\"`\n",
    "4. Always convert dashes (\"â€“\" or \"-\") to \"to\".\n",
    "5. If month is provided but not day (e.g., `\"April 2020 â€“ March 2021\"`), convert to `\"April 2020 to March 2021\"`.\n",
    "\n",
    "---\n",
    "\n",
    "### Task 3: Return a JSON in the following format:\n",
    "\n",
    "If a valid reporting year expression is found:\n",
    "\n",
    "{{\n",
    "  \"normalized_report_year\": \"your normalized result here\",\n",
    "  \"original_expression\": \"copy the original matched expression\",\n",
    "  \"source\": \"e.g. Page 1, main text\"\n",
    "}}\n",
    "\n",
    "If no valid expression is found:\n",
    "\n",
    "{{\n",
    "  \"normalized_report_year\": null,\n",
    "  \"original_expression\": null,\n",
    "  \"source\": \"NOT FOUND\"\n",
    "}}\n",
    "\n",
    "Only output the JSON object. Do not add explanations or commentary.\n",
    "\n",
    "---\n",
    "\n",
    "Text:\n",
    "{text}\n",
    "\"\"\"\n",
    "\n",
    "# ========== 5. Vision æ¨¡å‹è¾…åŠ© ==========\n",
    "def encode_image_to_base64(pil_image):\n",
    "    with tempfile.NamedTemporaryFile(suffix=\".png\") as f:\n",
    "        pil_image.save(f.name, format=\"PNG\")\n",
    "        with open(f.name, \"rb\") as image_file:\n",
    "            return base64.b64encode(image_file.read()).decode(\"utf-8\")\n",
    "\n",
    "def extract_year_from_vision(pdf_path, client, page_limit=10):\n",
    "    try:\n",
    "        images = convert_from_path(pdf_path, dpi=200)\n",
    "        for i, img in enumerate(images[:page_limit]):\n",
    "            b64 = encode_image_to_base64(img)\n",
    "            response = client.chat.completions.create(\n",
    "                model=\"gpt-4o\",\n",
    "                messages=[\n",
    "                    {\"role\": \"user\", \"content\": [\n",
    "                        {\"type\": \"text\", \"text\": f\"Please extract the fiscal year or reporting period from page {i+1}. Please return in this JSON format:\\n\"\n",
    "                                                 \"{\\n  \\\"normalized_report_year\\\": \\\"...\\\",\\n  \\\"original_expression\\\": \\\"...\\\",\\n  \\\"source\\\": \\\"Page {i+1}, image-based\\\"\\n}\"},\n",
    "                        {\"type\": \"image_url\", \"image_url\": {\"url\": f\"data:image/png;base64,{b64}\"}}\n",
    "                    ]}\n",
    "                ],\n",
    "                max_tokens=300\n",
    "            )\n",
    "            content = response.choices[0].message.content\n",
    "            parsed = json.loads(content.strip()) if content.strip().startswith(\"{\") else eval(content.strip())\n",
    "            if parsed.get(\"normalized_report_year\"):\n",
    "                return parsed\n",
    "    except Exception as e:\n",
    "        return {\n",
    "            \"normalized_report_year\": None,\n",
    "            \"original_expression\": None,\n",
    "            \"source\": f\"Vision ERROR: {e}\"\n",
    "        }\n",
    "    return {\n",
    "        \"normalized_report_year\": None,\n",
    "        \"original_expression\": None,\n",
    "        \"source\": \"Vision NOT FOUND\"\n",
    "    }\n",
    "\n",
    "# ========== 6. ä¸»å‡½æ•°ï¼šå…ˆæ–‡æœ¬ï¼Œå† Vision ==========\n",
    "def extract_report_year(pdf_path, client):\n",
    "    try:\n",
    "        text = extract_front_back_text(pdf_path)\n",
    "        prompt = build_report_year_prompt(text)\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-4.1-mini\",\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "            temperature=0,\n",
    "            max_tokens=500\n",
    "        )\n",
    "        content = response.choices[0].message.content\n",
    "        parsed = json.loads(content.strip()) if content.strip().startswith(\"{\") else eval(content.strip())\n",
    "        if parsed.get(\"normalized_report_year\"):\n",
    "            return parsed\n",
    "    except Exception as e:\n",
    "        print(f\"âš ï¸ GPT-4.1-mini failed on {Path(pdf_path).name}, fallback to Vision...\")\n",
    "    return extract_year_from_vision(pdf_path, client)\n",
    "\n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "# å¤šçº¿ç¨‹å¤„ç†å‡½æ•°\n",
    "def process_pdf(pdf_path):\n",
    "    try:\n",
    "        out = extract_report_year(str(pdf_path), client)\n",
    "        out[\"filename\"] = pdf_path.name\n",
    "    except Exception as e:\n",
    "        out = {\n",
    "            \"filename\": pdf_path.name,\n",
    "            \"normalized_report_year\": None,\n",
    "            \"original_expression\": None,\n",
    "            \"source\": f\"ERROR: {e}\"\n",
    "        }\n",
    "    return out\n",
    "\n",
    "def batch_extract_years_multithread(pdf_dir, output_csv=\"results/extracted_report_years_formal1.csv\", n_jobs=2):\n",
    "    pdf_dir = Path(pdf_dir)\n",
    "    pdf_files = sorted(pdf_dir.glob(\"*.pdf\"))\n",
    "    os.makedirs(Path(output_csv).parent, exist_ok=True)\n",
    "\n",
    "    # âœ… å¹¶è¡Œå¤„ç†\n",
    "    results = Parallel(n_jobs=n_jobs, prefer=\"threads\")(\n",
    "        delayed(process_pdf)(pdf) for pdf in tqdm(pdf_files, desc=\"ğŸ“„ Processing PDFs\")\n",
    "    )\n",
    "\n",
    "    df = pd.DataFrame(results)\n",
    "    df.to_csv(output_csv, index=False)\n",
    "    print(f\"\\nâœ… Extraction complete! Results saved to: {output_csv}\")\n",
    "\n",
    "# ========== 8. è¿è¡Œ ==========\n",
    "if __name__ == \"__main__\":\n",
    "    batch_extract_years_multithread(\"pdf_folder\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "986b71c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… å·²ä¿å­˜ç®€æ´å¯¹æ¯”ç»“æœä¸º rfyear_comparison_results_minimal.csv\n",
      "ğŸ“Š åŒ¹é…æƒ…å†µç»Ÿè®¡ï¼š\n",
      "match_result\n",
      "missing     389\n",
      "mismatch    116\n",
      "match        96\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# è¯»å–æ–‡ä»¶\n",
    "anno_df = pd.read_excel(\"check/rfyear_annotation.xlsx\")\n",
    "result_df = pd.read_csv(\"results/extracted_report_years_formal1.csv\")\n",
    "\n",
    "# æ¸…æ´—æ–‡ä»¶ååˆ—\n",
    "anno_df[\"pdf_name_clean\"] = anno_df[\"pdf_name\"].str.strip().str.lower()\n",
    "result_df[\"filename_clean\"] = result_df[\"filename\"].str.strip().str.lower()\n",
    "\n",
    "# åˆå¹¶ä¸¤ä¸ªè¡¨\n",
    "merged_df = pd.merge(\n",
    "    anno_df,\n",
    "    result_df,\n",
    "    left_on=\"pdf_name_clean\",\n",
    "    right_on=\"filename_clean\",\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "# å¹´ä»½å¯¹æ¯”å‡½æ•°\n",
    "def match_year(human, gpt):\n",
    "    if pd.isna(human) or pd.isna(gpt):\n",
    "        return \"missing\"\n",
    "    return \"match\" if str(human).strip().lower() == str(gpt).strip().lower() else \"mismatch\"\n",
    "\n",
    "# æ·»åŠ åŒ¹é…ç»“æœ\n",
    "merged_df[\"match_result\"] = merged_df.apply(\n",
    "    lambda row: match_year(row[\"chosen_rfyear\"], row[\"normalized_report_year\"]),\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# ä»…ä¿ç•™æœ‰ç”¨å­—æ®µ\n",
    "final_df = merged_df[[\n",
    "    \"pdf_name\", \"chosen_rfyear\", \"normalized_report_year\", \"match_result\"\n",
    "]]\n",
    "\n",
    "# ä¿å­˜ç»“æœ\n",
    "# final_df.to_csv(\"rfyear_comparison_results_minimal.csv\", index=False)\n",
    "\n",
    "# è¾“å‡ºç»Ÿè®¡\n",
    "print(\"âœ… å·²ä¿å­˜ç®€æ´å¯¹æ¯”ç»“æœä¸º rfyear_comparison_results_minimal.csv\")\n",
    "print(\"ğŸ“Š åŒ¹é…æƒ…å†µç»Ÿè®¡ï¼š\")\n",
    "print(final_df[\"match_result\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aa2420e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… åˆå¹¶æ ·æœ¬æ•°ï¼š224\n",
      "âœ… åŒ¹é…æ­£ç¡®æ•°ï¼š97\n",
      "âœ… å‡†ç¡®ç‡ï¼ˆaccuracyï¼‰ï¼š43.30%\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "# 1. è¯»å–ä¸¤ä¸ªæ–‡ä»¶\n",
    "gpt_df = pd.read_csv(\"results/extracted_report_years_formal1.csv\")  # æå–ç»“æœ\n",
    "label_df = pd.read_excel(\"check/rfyear_annotation.xlsx\")         # äººå·¥æ ‡æ³¨æ–‡ä»¶\n",
    "\n",
    "# 2. é‡å‘½ååˆ—ä»¥ä¾¿å¯¹é½åˆå¹¶\n",
    "gpt_df.rename(columns={\"filename\": \"pdf_name\", \"report_year\": \"normalized_report_year\"}, inplace=True)\n",
    "\n",
    "# 3. åˆå¹¶ä¸¤ä¸ªè¡¨ï¼ˆinner joinï¼Œåªä¿ç•™ä¸¤ä¸ªéƒ½æœ‰çš„ pdfï¼‰\n",
    "merged = pd.merge(label_df, gpt_df, on=\"pdf_name\", how=\"inner\")\n",
    "\n",
    "# 4. æ ‡å‡†åŒ–å­—ç¬¦ä¸²æ ¼å¼ï¼ˆå»é™¤ç©ºæ ¼å¤§å°å†™ç­‰ï¼‰\n",
    "merged[\"normalized_report_year\"] = merged[\"normalized_report_year\"].astype(str).str.strip().str.lower()\n",
    "merged[\"chosen_rfyear\"] = merged[\"chosen_rfyear\"].astype(str).str.strip().str.lower()\n",
    "\n",
    "# 5. å®šä¹‰åŒ¹é…é€»è¾‘ï¼ˆå®Œå…¨åŒ¹é…å³å¯ï¼‰\n",
    "merged[\"match\"] = merged[\"normalized_report_year\"] == merged[\"chosen_rfyear\"]\n",
    "\n",
    "# 6. ç»Ÿè®¡æŒ‡æ ‡\n",
    "total = len(merged)\n",
    "correct = merged[\"match\"].sum()\n",
    "accuracy = correct / total\n",
    "\n",
    "print(f\"âœ… åˆå¹¶æ ·æœ¬æ•°ï¼š{total}\")\n",
    "print(f\"âœ… åŒ¹é…æ­£ç¡®æ•°ï¼š{correct}\")\n",
    "print(f\"âœ… å‡†ç¡®ç‡ï¼ˆaccuracyï¼‰ï¼š{accuracy:.2%}\")\n",
    "\n",
    "# 7. å¯é€‰ï¼šä¿å­˜å¯¹æ¯”ç»“æœ\n",
    "# merged[[\"pdf_name\", \"chosen_rfyear\", \"report_year_pred\", \"match\"]].to_csv(\"eval/year_comparison.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5ab1cdeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Total matched records: 0\n",
      "âœ… Correct matches: 0\n",
      "âœ… Accuracy: nan%\n",
      "ğŸš¨ Mismatched cases saved to eval/year_mismatch_cases.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/9z/mm8bj8yn2yj6rk7vdlhpt07h0000gn/T/ipykernel_94143/460687779.py:22: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  accuracy = correct / total\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# 1. è¯»å–ä¸¤ä¸ªæ–‡ä»¶\n",
    "gpt_df = pd.read_csv(\"results/extracted_report_years_formal1.csv\")\n",
    "human_df = pd.read_excel(\"check/rfyear_annotation.xlsx\")  # ä¿®æ”¹ä¸ºä½ çš„è·¯å¾„\n",
    "\n",
    "# 2. å¯¹é½åˆ—åå¹¶åˆå¹¶ï¼ˆæŒ‰ PDF æ–‡ä»¶ååŒ¹é…ï¼‰\n",
    "gpt_df[\"pdf_name\"] = gpt_df[\"filename\"].str.replace(\".pdf\", \"\", regex=False)\n",
    "merged_df = pd.merge(human_df, gpt_df, on=\"pdf_name\", how=\"inner\")\n",
    "\n",
    "# 3. æ ‡å‡†åŒ–å¹´ä»½å­—ç¬¦ä¸²ï¼ˆä¸¤ä¾§ç©ºæ ¼ã€å°å†™ç­‰ï¼‰\n",
    "merged_df[\"chosen_rfyear_std\"] = merged_df[\"normalized_report_year\"].astype(str).str.strip().str.lower()\n",
    "merged_df[\"report_year_std\"] = merged_df[\"chosen_rfyear\"].astype(str).str.strip().str.lower()\n",
    "\n",
    "# 4. æ¯”å¯¹æ˜¯å¦å®Œå…¨ä¸€è‡´\n",
    "merged_df[\"is_match\"] = merged_df[\"chosen_rfyear_std\"] == merged_df[\"report_year_std\"]\n",
    "\n",
    "# 5. è¯„ä¼°å‡†ç¡®ç‡\n",
    "total = len(merged_df)\n",
    "correct = merged_df[\"is_match\"].sum()\n",
    "accuracy = correct / total\n",
    "\n",
    "# 6. è¾“å‡ºè¯„ä¼°ç»“æœ\n",
    "print(f\"âœ… Total matched records: {total}\")\n",
    "print(f\"âœ… Correct matches: {correct}\")\n",
    "print(f\"âœ… Accuracy: {accuracy:.2%}\")\n",
    "\n",
    "# 7. å¯è§†åŒ–é”™è¯¯æ¡ˆä¾‹\n",
    "errors = merged_df[~merged_df[\"is_match\"]][[\"pdf_name\", \"normalized_report_year\", \"chosen_rfyear\", \"source\"]]\n",
    "errors.to_csv(\"eval/year_mismatch_cases.csv\", index=False)\n",
    "print(\"ğŸš¨ Mismatched cases saved to eval/year_mismatch_cases.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a793833c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "irp_pdf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
