{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b3280ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "📄 Processing PDFs:   6%|▋         | 82/1277 [01:21<19:22,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ GPT-4.1-mini failed on Armstrong_Flooring_Inc_SustainabilityReport-2020_kot54emv.pdf, fallback to Vision...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "📄 Processing PDFs:   7%|▋         | 84/1277 [01:21<13:01,  1.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ GPT-4.1-mini failed on Arvind_Ltd_Arvind_AR_2022-23_0_iwp4673c.pdf, fallback to Vision...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "📄 Processing PDFs:   9%|▉         | 115/1277 [01:50<12:15,  1.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ GPT-4.1-mini failed on BASF_SE_2012_BASF_Report_lmq79gwn.pdf, fallback to Vision...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "📄 Processing PDFs:  12%|█▏        | 158/1277 [02:41<20:24,  1.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ GPT-4.1-mini failed on Boryung_Corporation_EBB3B4EBA0B920ECA780EC868DEAB080EB8AA5EAB2BDEC9881EBB3B4EAB3A0EC849CEC9881EBACB8_ebpit5lz.pdf, fallback to Vision...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "📄 Processing PDFs:  15%|█▍        | 190/1277 [03:16<21:49,  1.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ GPT-4.1-mini failed on COSCO_SHIPPING_Energy_Transportation_Co_Ltd_quality2022en_itv517g2.pdf, fallback to Vision...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "📄 Processing PDFs:  19%|█▉        | 240/1277 [04:32<18:48,  1.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ GPT-4.1-mini failed on Columbia_Banking_System_Inc__-Old_Annual20Progress20Report202022-23_huqi1n89.pdf, fallback to Vision...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "📄 Processing PDFs:  23%|██▎       | 290/1277 [05:53<27:54,  1.70s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ GPT-4.1-mini failed on EKI_Energy_Services_Limited_69298543284_zj7y1tjh.pdf, fallback to Vision...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "📄 Processing PDFs:  25%|██▍       | 316/1277 [06:21<19:11,  1.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ GPT-4.1-mini failed on Essential_Utilities_Inc_34ecde9c-8434-4849-a903-48114b59c681_f5v52887.pdf, fallback to Vision...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "📄 Processing PDFs:  32%|███▏      | 406/1277 [08:13<13:31,  1.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ GPT-4.1-mini failed on Hansae_Yes24_Holdings_Co_Ltd_HANSAE20YES2420HOLDINGS20ESG20REPORT202022_th5kzsfk.pdf, fallback to Vision...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "📄 Processing PDFs:  34%|███▍      | 434/1277 [08:45<16:20,  1.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ GPT-4.1-mini failed on Home_Inns__Hotels_Management_Inc_Barclays_Bank_PLC_Annual_Report_202014_5lj1epic.pdf, fallback to Vision...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "📄 Processing PDFs:  34%|███▍      | 440/1277 [08:51<16:08,  1.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ GPT-4.1-mini failed on Hyosung_Corp_SR_2020_en_8g98j6gk.pdf, fallback to Vision...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "📄 Processing PDFs:  72%|███████▏  | 920/1277 [18:43<06:51,  1.15s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ GPT-4.1-mini failed on Tam_Jai_International_Co_Ltd_2022083101184_go5rbp4a.pdf, fallback to Vision...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "📄 Processing PDFs:  78%|███████▊  | 992/1277 [20:06<05:57,  1.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ GPT-4.1-mini failed on Unknown_0720_FAO_Shifting_cultivation_livelihoodfood_security_j6g4r7xy.pdf, fallback to Vision...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "📄 Processing PDFs:  79%|███████▉  | 1014/1277 [20:40<04:48,  1.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ GPT-4.1-mini failed on Unknown_1901_4ch3st16.pdf, fallback to Vision...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "📄 Processing PDFs:  81%|████████▏ | 1040/1277 [21:06<03:04,  1.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ GPT-4.1-mini failed on Unknown_2014SustainRpt_FNL_lr_7mrwsfm7.pdf, fallback to Vision...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "📄 Processing PDFs:  92%|█████████▏| 1174/1277 [23:38<01:20,  1.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ GPT-4.1-mini failed on Unknown_2023042101335_kyzhtmjn.pdf, fallback to Vision...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "📄 Processing PDFs:  93%|█████████▎| 1192/1277 [24:04<02:30,  1.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ GPT-4.1-mini failed on Unknown_23076_Whitbread_AR2020_web_0v2mxh4f.pdf, fallback to Vision...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "📄 Processing PDFs: 100%|█████████▉| 1274/1277 [26:17<00:04,  1.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ GPT-4.1-mini failed on Unknown_adbi-managing-transition-low-carbon-economy_087is5zy.pdf, fallback to Vision...\n",
      "⚠️ GPT-4.1-mini failed on Unknown_adp07-sus-fr_95qx6prh.pdf, fallback to Vision...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "📄 Processing PDFs: 100%|██████████| 1277/1277 [26:17<00:00,  1.24s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Extraction complete! Results saved to: results/extracted_report_years_formal1.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import fitz  # PyMuPDF\n",
    "import openai\n",
    "import pytesseract\n",
    "import tempfile\n",
    "import base64\n",
    "import json\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from dotenv import load_dotenv\n",
    "from tqdm import tqdm\n",
    "from pdf2image import convert_from_path\n",
    "from PIL import Image\n",
    "from openai import OpenAI\n",
    "\n",
    "# ========== 1. 初始化 OpenAI ==========\n",
    "load_dotenv()\n",
    "client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "\n",
    "# ========== 2. 提取文本：前后20页 ==========\n",
    "def extract_front_back_text(pdf_path, front_n=10, back_n=10):\n",
    "    try:\n",
    "        doc = fitz.open(pdf_path)\n",
    "        texts = [doc[i].get_text() for i in range(min(front_n, len(doc)))]\n",
    "        texts += [doc[i].get_text() for i in range(max(0, len(doc) - back_n), len(doc))]\n",
    "        doc.close()\n",
    "        full_text = \"\\n\".join(texts)\n",
    "        if len(full_text.strip()) < 50:\n",
    "            raise ValueError(\"Too little text\")\n",
    "        return full_text\n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ PyMuPDF failed on {pdf_path.name}, switching to OCR...\")\n",
    "        return extract_text_with_ocr(pdf_path)\n",
    "\n",
    "# ========== 3. OCR 补救 ==========\n",
    "def extract_text_with_ocr(pdf_path, dpi=300):\n",
    "    with tempfile.TemporaryDirectory() as path:\n",
    "        images = convert_from_path(pdf_path, dpi=dpi, output_folder=path)\n",
    "        text_parts = [pytesseract.image_to_string(img) for img in images[:3] + images[-3:]]\n",
    "        return \"\\n\".join(text_parts)\n",
    "\n",
    "# ========== 4. 构造 Prompt ==========\n",
    "def build_report_year_prompt(text):\n",
    "    return f\"\"\"\n",
    "You are an expert assistant helping to extract reporting years from corporate reports.\n",
    "\n",
    "Please complete the following tasks after carefully reading the text below:\n",
    "\n",
    "---\n",
    "\n",
    "### Task 1: Identify any **fiscal year**, **reporting period**, or **financial year** expressions.\n",
    "\n",
    "Common examples include:\n",
    "- \"for the year ended 31 December 2021\"\n",
    "- \"reporting period: April 2021 – March 2022\"\n",
    "- \"2011–14\" or \"FY2017\"\n",
    "- \"2020 ESG highlights\"\n",
    "- \"2013 Corporate Report\"\n",
    "\n",
    "---\n",
    "\n",
    "### Task 2: Normalize each valid expression into a standardized format:\n",
    "\n",
    "1. If the expression is a **single year**, like `\"2013\"` or `\"FY2020\"`, output `\"2013\"` or `\"2020\"` as-is.\n",
    "2. If it is a **range of years only**, like `\"2014–15\"`, output `\"2014 to 2015\"`. Do **not** add months or days.\n",
    "3. If full dates are mentioned (e.g., `\"1st April 2020 – 31st March 2021\"`), remove ordinal suffixes (`1st`, `2nd`, etc.) and format as:\n",
    "   `\"1 April 2020 to 31 March 2021\"`\n",
    "4. Always convert dashes (\"–\" or \"-\") to \"to\".\n",
    "5. If month is provided but not day (e.g., `\"April 2020 – March 2021\"`), convert to `\"April 2020 to March 2021\"`.\n",
    "\n",
    "---\n",
    "\n",
    "### Task 3: Return a JSON in the following format:\n",
    "\n",
    "If a valid reporting year expression is found:\n",
    "\n",
    "{{\n",
    "  \"normalized_report_year\": \"your normalized result here\",\n",
    "  \"original_expression\": \"copy the original matched expression\",\n",
    "  \"source\": \"e.g. Page 1, main text\"\n",
    "}}\n",
    "\n",
    "If no valid expression is found:\n",
    "\n",
    "{{\n",
    "  \"normalized_report_year\": null,\n",
    "  \"original_expression\": null,\n",
    "  \"source\": \"NOT FOUND\"\n",
    "}}\n",
    "\n",
    "Only output the JSON object. Do not add explanations or commentary.\n",
    "\n",
    "---\n",
    "\n",
    "Text:\n",
    "{text}\n",
    "\"\"\"\n",
    "\n",
    "# ========== 5. Vision 模型辅助 ==========\n",
    "def encode_image_to_base64(pil_image):\n",
    "    with tempfile.NamedTemporaryFile(suffix=\".png\") as f:\n",
    "        pil_image.save(f.name, format=\"PNG\")\n",
    "        with open(f.name, \"rb\") as image_file:\n",
    "            return base64.b64encode(image_file.read()).decode(\"utf-8\")\n",
    "\n",
    "def extract_year_from_vision(pdf_path, client, page_limit=3):\n",
    "    try:\n",
    "        images = convert_from_path(pdf_path, dpi=200)\n",
    "        for i, img in enumerate(images[:page_limit]):\n",
    "            b64 = encode_image_to_base64(img)\n",
    "            response = client.chat.completions.create(\n",
    "                model=\"gpt-4o\",\n",
    "                messages=[\n",
    "                    {\"role\": \"user\", \"content\": [\n",
    "                        {\"type\": \"text\", \"text\": f\"Please extract the fiscal year or reporting period from page {i+1}. Please return in this JSON format:\\n\"\n",
    "                                                 \"{\\n  \\\"normalized_report_year\\\": \\\"...\\\",\\n  \\\"original_expression\\\": \\\"...\\\",\\n  \\\"source\\\": \\\"Page {i+1}, image-based\\\"\\n}\"},\n",
    "                        {\"type\": \"image_url\", \"image_url\": {\"url\": f\"data:image/png;base64,{b64}\"}}\n",
    "                    ]}\n",
    "                ],\n",
    "                max_tokens=300\n",
    "            )\n",
    "            content = response.choices[0].message.content\n",
    "            parsed = json.loads(content.strip()) if content.strip().startswith(\"{\") else eval(content.strip())\n",
    "            if parsed.get(\"normalized_report_year\"):\n",
    "                return parsed\n",
    "    except Exception as e:\n",
    "        return {\n",
    "            \"normalized_report_year\": None,\n",
    "            \"original_expression\": None,\n",
    "            \"source\": f\"Vision ERROR: {e}\"\n",
    "        }\n",
    "    return {\n",
    "        \"normalized_report_year\": None,\n",
    "        \"original_expression\": None,\n",
    "        \"source\": \"Vision NOT FOUND\"\n",
    "    }\n",
    "\n",
    "# ========== 6. 主函数：先文本，再 Vision ==========\n",
    "def extract_report_year(pdf_path, client):\n",
    "    try:\n",
    "        text = extract_front_back_text(pdf_path)\n",
    "        prompt = build_report_year_prompt(text)\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-4.1-mini\",\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "            temperature=0,\n",
    "            max_tokens=500\n",
    "        )\n",
    "        content = response.choices[0].message.content\n",
    "        parsed = json.loads(content.strip()) if content.strip().startswith(\"{\") else eval(content.strip())\n",
    "        if parsed.get(\"normalized_report_year\"):\n",
    "            return parsed\n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ GPT-4.1-mini failed on {Path(pdf_path).name}, fallback to Vision...\")\n",
    "    return extract_year_from_vision(pdf_path, client)\n",
    "\n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "# 多线程处理函数\n",
    "def process_pdf(pdf_path):\n",
    "    try:\n",
    "        out = extract_report_year(str(pdf_path), client)\n",
    "        out[\"filename\"] = pdf_path.name\n",
    "    except Exception as e:\n",
    "        out = {\n",
    "            \"filename\": pdf_path.name,\n",
    "            \"normalized_report_year\": None,\n",
    "            \"original_expression\": None,\n",
    "            \"source\": f\"ERROR: {e}\"\n",
    "        }\n",
    "    return out\n",
    "\n",
    "def batch_extract_years_multithread(pdf_dir, output_csv=\"results/extracted_report_years_formal1.csv\", n_jobs=2):\n",
    "    pdf_dir = Path(pdf_dir)\n",
    "    pdf_files = sorted(pdf_dir.glob(\"*.pdf\"))\n",
    "    os.makedirs(Path(output_csv).parent, exist_ok=True)\n",
    "\n",
    "    # ✅ 并行处理\n",
    "    results = Parallel(n_jobs=n_jobs, prefer=\"threads\")(\n",
    "        delayed(process_pdf)(pdf) for pdf in tqdm(pdf_files, desc=\"📄 Processing PDFs\")\n",
    "    )\n",
    "\n",
    "    df = pd.DataFrame(results)\n",
    "    df.to_csv(output_csv, index=False)\n",
    "    print(f\"\\n✅ Extraction complete! Results saved to: {output_csv}\")\n",
    "\n",
    "# ========== 8. 运行 ==========\n",
    "if __name__ == \"__main__\":\n",
    "    batch_extract_years_multithread(\"pdf_folder\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "986b71c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 已保存简洁对比结果为 rfyear_comparison_results_minimal.csv\n",
      "📊 匹配情况统计：\n",
      "match_result\n",
      "missing     389\n",
      "mismatch    115\n",
      "match        97\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 读取文件\n",
    "anno_df = pd.read_excel(\"check/rfyear_annotation.xlsx\")\n",
    "result_df = pd.read_csv(\"results/extracted_report_years_formal1.csv\")\n",
    "\n",
    "# 清洗文件名列\n",
    "anno_df[\"pdf_name_clean\"] = anno_df[\"pdf_name\"].str.strip().str.lower()\n",
    "result_df[\"filename_clean\"] = result_df[\"filename\"].str.strip().str.lower()\n",
    "\n",
    "# 合并两个表\n",
    "merged_df = pd.merge(\n",
    "    anno_df,\n",
    "    result_df,\n",
    "    left_on=\"pdf_name_clean\",\n",
    "    right_on=\"filename_clean\",\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "# 年份对比函数\n",
    "def match_year(human, gpt):\n",
    "    if pd.isna(human) or pd.isna(gpt):\n",
    "        return \"missing\"\n",
    "    return \"match\" if str(human).strip().lower() == str(gpt).strip().lower() else \"mismatch\"\n",
    "\n",
    "# 添加匹配结果\n",
    "merged_df[\"match_result\"] = merged_df.apply(\n",
    "    lambda row: match_year(row[\"chosen_rfyear\"], row[\"normalized_report_year\"]),\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# 仅保留有用字段\n",
    "final_df = merged_df[[\n",
    "    \"pdf_name\", \"chosen_rfyear\", \"normalized_report_year\", \"match_result\"\n",
    "]]\n",
    "\n",
    "# 保存结果\n",
    "# final_df.to_csv(\"rfyear_comparison_results_minimal.csv\", index=False)\n",
    "\n",
    "# 输出统计\n",
    "print(\"✅ 已保存简洁对比结果为 rfyear_comparison_results_minimal.csv\")\n",
    "print(\"📊 匹配情况统计：\")\n",
    "print(final_df[\"match_result\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aa2420e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 合并样本数：224\n",
      "✅ 匹配正确数：97\n",
      "✅ 准确率（accuracy）：43.30%\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "# 1. 读取两个文件\n",
    "gpt_df = pd.read_csv(\"results/extracted_report_years_formal1.csv\")  # 提取结果\n",
    "label_df = pd.read_excel(\"check/rfyear_annotation.xlsx\")         # 人工标注文件\n",
    "\n",
    "# 2. 重命名列以便对齐合并\n",
    "gpt_df.rename(columns={\"filename\": \"pdf_name\", \"report_year\": \"normalized_report_year\"}, inplace=True)\n",
    "\n",
    "# 3. 合并两个表（inner join，只保留两个都有的 pdf）\n",
    "merged = pd.merge(label_df, gpt_df, on=\"pdf_name\", how=\"inner\")\n",
    "\n",
    "# 4. 标准化字符串格式（去除空格大小写等）\n",
    "merged[\"normalized_report_year\"] = merged[\"normalized_report_year\"].astype(str).str.strip().str.lower()\n",
    "merged[\"chosen_rfyear\"] = merged[\"chosen_rfyear\"].astype(str).str.strip().str.lower()\n",
    "\n",
    "# 5. 定义匹配逻辑（完全匹配即可）\n",
    "merged[\"match\"] = merged[\"normalized_report_year\"] == merged[\"chosen_rfyear\"]\n",
    "\n",
    "# 6. 统计指标\n",
    "total = len(merged)\n",
    "correct = merged[\"match\"].sum()\n",
    "accuracy = correct / total\n",
    "\n",
    "print(f\"✅ 合并样本数：{total}\")\n",
    "print(f\"✅ 匹配正确数：{correct}\")\n",
    "print(f\"✅ 准确率（accuracy）：{accuracy:.2%}\")\n",
    "\n",
    "# 7. 可选：保存对比结果\n",
    "merged[[\"pdf_name\", \"chosen_rfyear\", \"normalized_report_year\", \"match\"]].to_csv(\"eval/year_comparison1.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1f0a0901",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 合并样本数：224\n",
      "✅ 匹配正确数：178\n",
      "✅ 模糊匹配准确率（Fuzzy Accuracy）：79.46%\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# === 1. 加载数据 ===\n",
    "gpt_df = pd.read_csv(\"results/extracted_report_years_formal1.csv\")  # GPT提取结果\n",
    "label_df = pd.read_excel(\"check/rfyear_annotation.xlsx\")            # 标注结果\n",
    "\n",
    "# === 2. 重命名列对齐、合并（按文件名）===\n",
    "gpt_df.rename(columns={\"filename\": \"pdf_name\", \"report_year\": \"normalized_report_year\"}, inplace=True)\n",
    "merged = pd.merge(label_df, gpt_df, on=\"pdf_name\", how=\"inner\")\n",
    "\n",
    "# === 3. 清洗文本：空值转空串，大小写、空格、换行处理 ===\n",
    "def clean_text(s):\n",
    "    if pd.isna(s): return \"\"\n",
    "    return str(s).strip().lower().replace(\"\\n\", \" \")\n",
    "\n",
    "merged[\"normalized_report_year\"] = merged[\"normalized_report_year\"].apply(clean_text)\n",
    "merged[\"chosen_rfyear\"] = merged[\"chosen_rfyear\"].apply(clean_text)\n",
    "\n",
    "# === 4. 定义辅助函数 ===\n",
    "import re\n",
    "\n",
    "def normalize_year_text(s):\n",
    "    if not s:\n",
    "        return \"\"\n",
    "    s = s.lower()\n",
    "\n",
    "    # 去掉标点与多余字符\n",
    "    s = re.sub(r'[\\(\\)\\[\\],;:]', ' ', s)\n",
    "    s = re.sub(r'\\s+', ' ', s)\n",
    "    s = re.sub(r'[^a-z0-9\\s\\-/–]', ' ', s)\n",
    "\n",
    "    # 替换 FY 缩写和连接符为 to\n",
    "    s = s.replace(\"–\", \"to\").replace(\"-\", \"to\").replace(\"/\", \"to\")\n",
    "    s = re.sub(r'\\bfy\\b', 'fiscal year', s)\n",
    "    s = re.sub(r'\\bfy(\\d{2})\\b', lambda m: f\"20{m.group(1)}\", s)  # fy20 → 2020\n",
    "    s = re.sub(r'\\bfy\\s*(\\d{4})\\b', r'\\1', s)\n",
    "\n",
    "    # 展开缩写年份如 2022–23 → 2022 to 2023\n",
    "    s = re.sub(r'\\b(20\\d{2})\\s*to\\s*(\\d{2})\\b', lambda m: f\"{m.group(1)} to 20{m.group(2)}\", s)\n",
    "    s = re.sub(r'\\b(20\\d{2})\\s*[\\-–]\\s*(\\d{2})\\b', lambda m: f\"{m.group(1)} to 20{m.group(2)}\", s)\n",
    "    s = re.sub(r'\\b(20\\d{2})[\\-–](20\\d{2})\\b', r'\\1 to \\2', s)\n",
    "    s = re.sub(r'\\b(20\\d{2})\\s+to\\s+(20\\d{2})\\b', r'\\1 to \\2', s)\n",
    "\n",
    "    # 清理序数词，如 1st, 2nd, 3rd\n",
    "    s = re.sub(r'\\b(\\d{1,2})(st|nd|rd|th)\\b', r'\\1', s)\n",
    "\n",
    "    # 统一日期格式，如 \"31 march 2023\" → \"31 march 2023\"\n",
    "    s = s.strip()\n",
    "    return s\n",
    "\n",
    "def extract_years(s):\n",
    "    return sorted(set(re.findall(r'\\b(20\\d{2}|19\\d{2})\\b', s)))\n",
    "\n",
    "def is_fuzzy_match(a, b):\n",
    "    a_norm = normalize_year_text(a)\n",
    "    b_norm = normalize_year_text(b)\n",
    "    if a_norm == b_norm:\n",
    "        return True\n",
    "    a_years = extract_years(a_norm)\n",
    "    b_years = extract_years(b_norm)\n",
    "    if not a_years or not b_years:\n",
    "        return False\n",
    "    # 年份集合完全一致 or 包含关系\n",
    "    if set(a_years) == set(b_years):\n",
    "        return True\n",
    "    if len(a_years) == 1 and a_years[0] in b_years:\n",
    "        return True\n",
    "    if len(b_years) == 1 and b_years[0] in a_years:\n",
    "        return True\n",
    "    # 仅一个年份时近似判断\n",
    "    if len(a_years) == 1 and len(b_years) == 1 and abs(int(a_years[0]) - int(b_years[0])) <= 1:\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "# === 5. 应用模糊匹配函数 ===\n",
    "merged[\"fuzzy_match\"] = merged.apply(lambda row: is_fuzzy_match(row[\"normalized_report_year\"], row[\"chosen_rfyear\"]), axis=1)\n",
    "\n",
    "# === 6. 计算准确率 ===\n",
    "total = len(merged)\n",
    "correct = merged[\"fuzzy_match\"].sum()\n",
    "accuracy = correct / total\n",
    "\n",
    "print(f\"✅ 合并样本数：{total}\")\n",
    "print(f\"✅ 匹配正确数：{correct}\")\n",
    "print(f\"✅ 模糊匹配准确率（Fuzzy Accuracy）：{accuracy:.2%}\")\n",
    "\n",
    "# === 7. 保存结果 ===\n",
    "merged[[\"pdf_name\", \"chosen_rfyear\", \"normalized_report_year\", \"fuzzy_match\"]].to_csv(\"eval/year_comparison3.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a793833c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ number of combine samples：224\n",
      "✅ correct matches：189\n",
      "✅ Fuzzy Accuracy：84.38%\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# === 1. 加载数据 ===\n",
    "gpt_df = pd.read_csv(\"results/extracted_report_years_formal1.csv\")  # GPT提取结果\n",
    "label_df = pd.read_excel(\"check/rfyear_annotation.xlsx\")            # 标注结果\n",
    "\n",
    "# === 2. 重命名列对齐、合并（按文件名）===\n",
    "gpt_df.rename(columns={\"filename\": \"pdf_name\", \"report_year\": \"normalized_report_year\"}, inplace=True)\n",
    "merged = pd.merge(label_df, gpt_df, on=\"pdf_name\", how=\"inner\")\n",
    "\n",
    "# === 3. 清洗文本：空值转空串，大小写、空格、换行处理 ===\n",
    "def clean_text(s):\n",
    "    if pd.isna(s): return \"\"\n",
    "    return str(s).strip().lower().replace(\"\\n\", \" \")\n",
    "\n",
    "merged[\"normalized_report_year\"] = merged[\"normalized_report_year\"].apply(clean_text)\n",
    "merged[\"chosen_rfyear\"] = merged[\"chosen_rfyear\"].apply(clean_text)\n",
    "\n",
    "# === 4. 定义辅助函数 ===\n",
    "import re\n",
    "\n",
    "def normalize_year_text(s):\n",
    "    if not s:\n",
    "        return \"\"\n",
    "    s = s.lower().strip()\n",
    "    \n",
    "    # 替换常见连字符为统一格式\n",
    "    s = s.replace(\"–\", \" to \").replace(\"-\", \" to \").replace(\"/\", \" to \")\n",
    "\n",
    "    # 清除无效字符\n",
    "    s = re.sub(r'[\\(\\)\\[\\],;:]', ' ', s)\n",
    "    s = re.sub(r'\\s+', ' ', s)\n",
    "\n",
    "    # fy 缩写处理：fy2020 或 fy 2020 → 2020\n",
    "    s = re.sub(r'\\bfy\\s*(\\d{4})\\b', r'\\1', s)                   # fy 2020 → 2020\n",
    "    s = re.sub(r'\\bfy\\s*(\\d{2})\\b', lambda m: f\"20{m.group(1)}\", s)  # fy 19 → 2019\n",
    "\n",
    "    # 区间格式处理：2020 to 21 → 2020 to 2021\n",
    "    s = re.sub(r'\\b(20\\d{2})\\s+to\\s+(\\d{2})\\b', lambda m: f\"{m.group(1)} to 20{m.group(2)}\", s)\n",
    "\n",
    "    # 区间格式处理：2020–2021、2020-2021、fy2020 to 2021 → 2020 to 2021\n",
    "    s = re.sub(r'\\b(20\\d{2})\\s*to\\s*(20\\d{2})\\b', r'\\1 to \\2', s)\n",
    "    s = re.sub(r'\\b(20\\d{2})\\s+to\\s+20\\d{2}', r'\\g<0>', s)\n",
    "\n",
    "    # 清理序数词\n",
    "    s = re.sub(r'\\b(\\d{1,2})(st|nd|rd|th)\\b', r'\\1', s)\n",
    "\n",
    "    return s.strip()\n",
    "\n",
    "def extract_years(s):\n",
    "    return sorted(set(re.findall(r'\\b(20\\d{2}|19\\d{2})\\b', s)))\n",
    "\n",
    "def is_fuzzy_match(a, b):\n",
    "    a_norm = normalize_year_text(a)\n",
    "    b_norm = normalize_year_text(b)\n",
    "    if a_norm == b_norm:\n",
    "        return True\n",
    "\n",
    "    # 提取年份集合\n",
    "    a_years = extract_years(a_norm)\n",
    "    b_years = extract_years(b_norm)\n",
    "\n",
    "    if not a_years or not b_years:\n",
    "        return False\n",
    "\n",
    "    # 排序后再比较\n",
    "    a_sorted = sorted(set(a_years))\n",
    "    b_sorted = sorted(set(b_years))\n",
    "\n",
    "    # 完全一致或包含\n",
    "    if a_sorted == b_sorted:\n",
    "        return True\n",
    "    if len(a_sorted) == 1 and a_sorted[0] in b_sorted:\n",
    "        return True\n",
    "    if len(b_sorted) == 1 and b_sorted[0] in a_sorted:\n",
    "        return True\n",
    "\n",
    "    # 仅一个年份时允许±1\n",
    "    if len(a_sorted) == 1 and len(b_sorted) == 1 and abs(int(a_sorted[0]) - int(b_sorted[0])) <= 1:\n",
    "        return True\n",
    "\n",
    "    return False\n",
    "\n",
    "# === 5. 应用模糊匹配函数 ===\n",
    "merged[\"fuzzy_match\"] = merged.apply(lambda row: is_fuzzy_match(row[\"normalized_report_year\"], row[\"chosen_rfyear\"]), axis=1)\n",
    "\n",
    "# === 6. 计算准确率 ===\n",
    "total = len(merged)\n",
    "correct = merged[\"fuzzy_match\"].sum()\n",
    "accuracy = correct / total\n",
    "\n",
    "print(f\"✅ number of combine samples：{total}\")\n",
    "print(f\"✅ correct matches：{correct}\")\n",
    "print(f\"✅ Fuzzy Accuracy：{accuracy:.2%}\")\n",
    "\n",
    "# === 7. 保存结果 ===\n",
    "merged[[\"pdf_name\", \"chosen_rfyear\", \"normalized_report_year\", \"fuzzy_match\"]].to_csv(\"eval/year_comparison3.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9231e7e9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "irp_pdf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
